<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>janf</title>
<link>https://janf.cc/index.html</link>
<atom:link href="https://janf.cc/index.xml" rel="self" type="application/rss+xml"/>
<description>janf.cc</description>
<generator>quarto-1.3.433</generator>
<lastBuildDate>Sat, 23 Sep 2023 22:00:00 GMT</lastBuildDate>
<item>
  <title>data ethics</title>
  <dc:creator>janf </dc:creator>
  <link>https://janf.cc/posts/2023-09-24_data_ethics/data_ethics_post.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-09-24_data_ethics/data_ethics_thumbnail.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">fastai book chapter 3 - janf - 2023</figcaption>
</figure>
</div>
<section id="intro" class="level1">
<h1>Intro</h1>
<p>This my summary of chapter 3 from the book ‘Deep Learning for Coders with fastai &amp; PyTorch’.</p>
<ul>
<li>questions - question about the chapter</li>
<li>key concepts - summarized key concepts of the chapter</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Links
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Homepage: <a href="https://www.fast.ai/">fastai hompage</a></li>
<li>Online Book: <a href="https://course.fast.ai/Resources/book.html">fastai online book</a></li>
<li>Author: <a href="https://jeremy.fast.ai/">jermey howard</a></li>
<li>Author: <a href="https://sgugger.github.io/">sylvain gugger</a></li>
<li>Co-Author of this chapter: <a href="https://rachel.fast.ai/about.html">rachel thomas</a></li>
</ul>
</div>
</div>
</section>
<section id="questions" class="level1">
<h1>Questions</h1>
<p>Questions about the chapter.</p>
<p><a href="../../posts/2023-09-24_data_ethics/subsite/data_ethics_questions.html">Questions - Chapter 3 - Data Ethics</a></p>
</section>
<section id="code" class="level1">
<h1>Code</h1>
<p>No code for this chapter.</p>
</section>
<section id="key-concepts" class="level1">
<h1>Key Concepts</h1>
<p>Summarized key concepts ot this chapter.</p>
<section id="why-do-data-ethics-matter" class="level2">
<h2 class="anchored" data-anchor-id="why-do-data-ethics-matter">Why do Data Ethics Matter</h2>
<p>Everybody who is training models needs to consider how their models will be used, and consider how to best ensure that they are used as positively as possible. There are things you can do. And if you don’t do them things can go pretty badly. In general there are many negative societal consequences linked to AI an machine learning being observed today (bugs, flawed feedback loops, biases). It’not just a moral burden to consider sometimes there a legal burdens also. As example the first person who was jailed in the Volkswagen diesel scandal was the engineer not the manager. There is no final solution to ensure your work is used the right way. But with the right questions, you can at the very least ensure that the right issues are being considered. And you can so “no” to questionable pieces of work if their moral aspects don’t align.</p>
</section>
<section id="topics-in-data-ethics" class="level2">
<h2 class="anchored" data-anchor-id="topics-in-data-ethics">Topics in Data Ethics</h2>
<p>Data ethics is a big field. This summery doesn’t cover everything. The following are relevant topics to consider:</p>
<section id="recourse-and-accountability" class="level3">
<h3 class="anchored" data-anchor-id="recourse-and-accountability">Recourse and Accountability</h3>
<p>In a complex system, it is easy for no one person to feel responsible for outcomes. While this understandable, it does not lead to good results. To hinder big errors you need Recourse and Accountability. An additional reason why recourse is so necessary is that data often contains errors. Mechanism for audits and error correction are crucial and should be considered by by practitioners.</p>
</section>
<section id="feedback-loops" class="level3">
<h3 class="anchored" data-anchor-id="feedback-loops">Feedback Loops</h3>
<p>Feedback loops describe how an algorithm can interact with its environment to make predictions that reinforce action taken in the real world, which lead to predictions even more pronounced in the sam direction. Part of this problem is the driving metric of the algorithm. An algorithm has a metric to optimize, it will do everything it can to optimize their result. This can lead to all kinds of edge cases, and humans interacting with a system will search for, find, and exploit thees edge cases and feedback loops for their advantage. This behavior of feedback loops and tendencies for optimization can happen. As practitioner you should keep that in your mind and either anticipate a feedback loop and take positive action to break it when it happens.</p>
</section>
<section id="bias" class="level3">
<h3 class="anchored" data-anchor-id="bias">Bias</h3>
<p>Bias in machine learning can come from multiple sources. In this section we summarize the types of bias that are most helpful for machine learning projects.</p>
<ul>
<li><i>Historical bias</i>
<ul>
<li>Historical bias comes from the fact that people are biased, processes are biased, and society is biased. It is fundamental, structural issue with the first step of the data generation process and can exit even give perfect sampling and feature selection.</li>
</ul></li>
<li><i>Measurement bias</i>
<ul>
<li>Measurement bias can occur when our model makes mistakes because we are measuring the wrong thing, or measuring it in the wrong way, or incorporating that measurement into the model inappropriately.</li>
</ul></li>
<li><i>Aggregation bias</i>
<ul>
<li>Aggregation bias occurs when models do not aggregate data in a way that incorporates all of the appropriate factors, or when a model does not include the necessary interaction terms, nonlinearities, or so froth.</li>
</ul></li>
<li><i>Representation bias</i>
<ul>
<li>When the model emphasize some property of the data as it seemingly has the closet correlation with the prediction, even though that might not be the truth.</li>
</ul></li>
<li><i>Evaluation bias</i>
<ul>
<li>Evaluation bias occurs when the benchmark data used for a particular task does not represent the use population. A model is optimized on its training data, but its quality is often measured on benchmarks. These benchmark encourages the development and deployment of models that perform well only on the subset of the data represented by the benchmark data.</li>
</ul></li>
<li><i>Deployment bias</i>
<ul>
<li>Deployment bias arises when there is a mismatch between the problem a model is intended to solve and the way in which it is actually used. This often occurs when a system is built an evaluated as if were fully autonomous, while in reality, it operates in a complicated sociotechnical system moderated by human decision-makers.</li>
</ul></li>
</ul>
<p><i>Addressing different types of bias</i></p>
<p>Different types of bias require different approaches for mitigation. All datasets contain bias. There is no such thing as a complete debiased dataset. Many researchers in the field have been converging on a set of proposals to enable better documentation of the decisions, context, and specifics about how and why a particular dataset was created, what scenarios it is appropriate to use in, and what the limitations are. This way, those using a particular dataset will not be caught off guard by its biases and limitations.</p>
<p>Consider these points when working with machine learning algorithms:</p>
<ul>
<li>Machines learning can create feedback loops
<ul>
<li>Small amounts of bias can rapidly increase exponentially because of feedback loops.</li>
</ul></li>
<li>Machine learning can amplify bias
<ul>
<li>Human bias can lead to larger amounts of machine learning bias.</li>
</ul></li>
<li>Algorithms and humans are used differently
<ul>
<li>Human decisions makers and algorithmic decision makers are not used in a plug-and-play interchangeable way in practice. These examples are given in the list on the next page.</li>
</ul></li>
<li>Technology is power
<ul>
<li>And with that comes responsibility.</li>
</ul></li>
</ul>
</section>
</section>
<section id="disinformation" class="level2">
<h2 class="anchored" data-anchor-id="disinformation">Disinformation</h2>
<p>Disinformation is not necessarily about getting someone to believe something false, but rather often used to sow disharmony and uncertainty, and to get people to give up on seeking the truth. Is can often contain some seeds of truth, of half-truth taken out of context.</p>
<p>With machine learning disinformation can be created cheaper and at a larger scale. Trough autogenerated text machine learning can be used to create coordinated campaigns of inauthentic behavior. For instance, fraudulent accounts may try to make it seem like many people hold a particular viewpoint.</p>
</section>
<section id="addressing-ethical-issues" class="level2">
<h2 class="anchored" data-anchor-id="addressing-ethical-issues">Addressing Ethical Issues</h2>
<p>The issues raised within data ethics are often complex and interdisciplinary, but it is crucial that we work to address them. So what can we do?</p>
<p><i>Analyze a Project You Are Working On</i></p>
<ul>
<li>Consider the ethical implication of your work. Question to ask?
<ul>
<li>Should we even be doing this?</li>
<li>What bias is in the data?</li>
<li>Can the code and data be audited?</li>
<li>What processes are in place to handle appeals or mistakes?</li>
</ul></li>
</ul>
<p><i>Processes to Implement</i></p>
<ul>
<li>Concrete practices to implement to proactively search for ethical risks.
<ul>
<li>Expanding the ethical circle to include the perspectives of a variety of stakeholder.</li>
<li>Consult interests, desires, skills, experiences, and values that maybe were simply assumed.</li>
<li>Consider all stakeholders and their interests. Also the individuals that will be indirectly affected by our products.</li>
<li>Also consider terrible people. Who might use this product in ways we didn’t expected.</li>
</ul></li>
</ul>
<p><i>The Power of Diversity</i></p>
<ul>
<li>When everybody on a team has similar backgrounds, they are likely to have similar blind spots around ethical risks. Diversity can lead to problems being identified earlier, and a wider range of solutions being considered.</li>
</ul>
<p><i>Fairness, Accountability, and Transparency</i></p>
<ul>
<li>Treat fairness as a central concern rather than an afterthought. Don’t sidestep deeper questions about fairness, accountability and transparency.</li>
</ul>
<p><i>Regulation, Rights and Policy</i></p>
<ul>
<li>Policies are an appropriate tool for addressing data ethics issues when is likely that design fixes, self regulation and technical approaches to addressing problems, involving ethical uses of Machine Learning are not working. While such measures can be useful, they will not be sufficient to address the underlying problems that have led to our current state. For example, as long as it is incredibly profitable to create addictive technology, companies will continue to do so, regardless of whether this has the side effect of promoting conspiracy theories and polluting our information ecosystem. While individual designers may try to tweak product designs, we will not see substantial changes until the underlying profit incentives changes. Because of the above it is almost certain that policies will have to be created by government to address these issues.</li>
</ul>


</section>
</section>

 ]]></description>
  <category>fastai</category>
  <category>deeplearning</category>
  <category>self-study</category>
  <guid>https://janf.cc/posts/2023-09-24_data_ethics/data_ethics_post.html</guid>
  <pubDate>Sat, 23 Sep 2023 22:00:00 GMT</pubDate>
  <media:content url="https://janf.cc/posts/2023-09-24_data_ethics/data_ethics_thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>from model to production</title>
  <dc:creator>janf </dc:creator>
  <link>https://janf.cc/posts/2023-08-18_from_model_to_production/from_model_to_production_post.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-08-18_from_model_to_production/from_model_to_production_thumbnail.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">fastai book chapter 2 - janf - 2023</figcaption>
</figure>
</div>
<section id="intro" class="level1">
<h1>Intro</h1>
<p>This my summary of chapter 2 from the book ‘Deep Learning for Coders with fastai &amp; PyTorch’.</p>
<ul>
<li>questions - question about the chapter</li>
<li>key concepts - summarized key concepts of the chapter</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Links
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Homepage: <a href="https://www.fast.ai/">fastai hompage</a></li>
<li>Online Book: <a href="https://course.fast.ai/Resources/book.html">fastai online book</a></li>
<li>Author: <a href="https://jeremy.fast.ai/">jermey howard</a></li>
<li>Author: <a href="https://sgugger.github.io/">sylvain gugger</a></li>
</ul>
</div>
</div>
</section>
<section id="questions" class="level1">
<h1>Questions</h1>
<p>Questions about the chapter.</p>
<p><a href="../../posts/2023-08-18_from_model_to_production/subsite/from_model_to_production_questions.html">Questions - Chapter 2 - Your deep learning journey</a></p>
</section>
<section id="code" class="level1">
<h1>Code</h1>
<p>Code from this chapter.</p>
<p><a href="https://github.com/xjanfcc/fastai/blob/master/book/chapter_2_from_model_to_production/bears.ipynb">Code - Chapter 2 - From a model to production - Bears</a></p>
<p><a href="https://github.com/xjanfcc/fastai/blob/master/course/part_1-2_deployment/dog_cats.ipynb">Code - Course 1-2 - Deployment - Dog or Cat</a></p>
<p><a href="https://huggingface.co/spaces/xjanfcc/dog_cats/tree/main">Code - Course 1-2 - Deployment - Gradio Dog or Cat App Code</a></p>
<p><a href="https://huggingface.co/spaces/xjanfcc/dog_cats">Code - Course 1-2 - Deployment - Gradio Dog or Cat App</a></p>
<p><a href="https://github.com/xjanfcc/minimal-githubpage">Code - Course 1-2 - Minimal Github Pages Code</a></p>
<p><a href="https://xjanfcc.github.io/minimal-githubpage/">Code - Course 1-2 - Minimal Github Pages Website</a></p>
</section>
<section id="key-concepts" class="level1">
<h1>Key Concepts</h1>
<p>Summarized key concepts ot this chapter.</p>
<section id="drivetrain-approach" class="level2">
<h2 class="anchored" data-anchor-id="drivetrain-approach">Drivetrain Approach</h2>
<p>Data products get more and more complex so we sometimes lose sight of the real problem we are trying to solve. The Drivetrain Approach aims to better couple the data science to the real business needs/real world problem and to use data not just to generate more data but to use data to produce actionable outcomes.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-08-18_from_model_to_production/drivetrain_approach.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Drive Train Approach - Designing great data products</figcaption>
</figure>
</div>
<ol type="1">
<li>(Defined Objective) First we must define the objective / goal</li>
<li>(Levers) Specify what inputs/levers of the system we control that influence the final outcome</li>
<li>(Data) Determine what data to collect</li>
<li>(Models) Building the predictive models</li>
</ol>
</section>
<section id="dataloader-dataloaders-datablock" class="level2">
<h2 class="anchored" data-anchor-id="dataloader-dataloaders-datablock">DataLoader, DataLoaders, DataBlock</h2>
<ul>
<li><b>DataBlock</b> is the data pipeline. A template that we create that has no data, but defines all the context on how to work with it. For example, how to split the data, the data types of or features and targets/labels, how to extract the labels from the underlying data (folders).</li>
<li><b>DataLoader</b> doesn’t care about preparing data, it expects the data is ready to go and only cares about how to load the data (e.g.&nbsp;whether in parallel or in a single process) as well as feeding the data to the model in batches (i.e.&nbsp;batch size)</li>
<li><b>DataLoaders</b> is a thin wrapper for more than one DataLoader.</li>
</ul>
<p>A DataLoaders, is a thin class that automatically generates multiple <b>DataLoader</b> objects based on the rules specified in our <b>DataBlock</b></p>
<p>Example of a DataLoaders with a DataBlock Api:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">bears <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataBlock(</span>
<span id="cb1-2">blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(ImageBlock, CategoryBlock),</span>
<span id="cb1-3">get_items<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>get_image_files,</span>
<span id="cb1-4">splitter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>RandomSplitter(valid_pct<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>),</span>
<span id="cb1-5">get_y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>parent_label,</span>
<span id="cb1-6">item_tfms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Resize(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>)</span>
<span id="cb1-7">)</span></code></pre></div>
<p>These are the main parameters of the DataBlock:</p>
<ol type="1">
<li>blocks: is where you define the types of input and output data your model will work with. The first one is the independent (input) and the second one is dependent target. Usually you will have two input and output but you can have multiple input/output variables.</li>
<li>get_items: tells fastai how and where to get the files/data when needed.</li>
<li>splitter: how to split the data in training and validation set. Seeds are optional for replicability.</li>
<li>get_y: how to extract the target/label/variable (dependent) from the data.</li>
</ol>
</section>
<section id="data-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h2>
<p>Data augmentation refers to creating random variations of our input data, such that they appear different but do not change the meaning of the data. Examples of common data augmentation techniques for images are rotation, flipping, perspective warping, brightness changes and contrast changes. Data augmentation is useful for the model to better understand the basic concept of what an object is and how the objects of interest are represented in images. Therefore, data augmentation allows machine learning models to generalize better. This is especially important when it can be slow and expensive to label data.</p>
</section>
<section id="clean-the-data-with-you-model" class="level2">
<h2 class="anchored" data-anchor-id="clean-the-data-with-you-model">Clean the Data with you Model</h2>
<p>On method to look at your model is visualizing it in a confusion matrix:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-08-18_from_model_to_production/confusionmatrix.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">confusion matrix bears</figcaption>
</figure>
</div>
<p>For this example the rows represent all the black, grizzly and teddy bears in our dataset, respectively. The columns represent the images that the model predicted as black, grizzly and teddy bears, respectively. Therefore, the diagonal of the matrix shows the images that were classified correctly, and the off-diagonal cells represent those that were classified incorrectly.</p>
<p>A confusion matrix is helpful to see where exactly our errors occurring 1. You can see if there are datasets errors (images with no bears or entries labeled incorrectly) 2. Or you can see if there is problem with the model (images with unusual lighting or blurred images)</p>
<p>The intuitive approach to doing data cleaning is to do it before you train a model. But you can also train a quick and simple model first, and then use it to help us with data cleaning. fastai includes a handy GUI for data cleaning called ImageClassifierCleaner that allows you to choose a category and the training versus validation set and view the highest-loss images (in order), along with menus to allow images to be selected for removal or relabeling:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">cleaner <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ImageClassifierCleaner(learn)</span>
<span id="cb2-2">cleaner</span></code></pre></div>
</section>
<section id="avoid-disasters" class="level2">
<h2 class="anchored" data-anchor-id="avoid-disasters">Avoid Disasters</h2>
<p>You should always have in mind that it’s difficult to understand the behavior of a deep learning model. In a neural network the behavior emerges from the models attempt to match the training data, rather than being exactly defined.</p>
<p>One general problem is the out-of-domain data problem. That is to say, there may be data that our model sees in production that is very different from what it saw during training. There isn’t a complete technical solution to this problem, instead, we have to be careful about rolling out a deep learning model.</p>
<p>Another problem ist a domain is a domain shift, whereby the type of data that our model sees changes over time. For instance, an insurance company may use a deep learning model ass part of its pricing and risk algorithm, but over time the types of customers the company attracts and the types of risks it represents may change so much that the original training data is no longer relevant.</p>
<p>High-Level approach to mitigate the risks on a roll-out</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-08-18_from_model_to_production/rollout.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Mitigate risk on rollout</figcaption>
</figure>
</div>


</section>
</section>

 ]]></description>
  <category>fastai</category>
  <category>deeplearning</category>
  <category>self-study</category>
  <guid>https://janf.cc/posts/2023-08-18_from_model_to_production/from_model_to_production_post.html</guid>
  <pubDate>Thu, 17 Aug 2023 22:00:00 GMT</pubDate>
  <media:content url="https://janf.cc/posts/2023-08-18_from_model_to_production/from_model_to_production_thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>your deep learning journey</title>
  <dc:creator>janf </dc:creator>
  <link>https://janf.cc/posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_thumbnail.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">fastai book chapter 1 - janf - 2023</figcaption>
</figure>
</div>
<section id="intro" class="level1">
<h1>Intro</h1>
<p>This my summary of chapter 1 from the book ‘Deep Learning for Coders with fastai &amp; PyTorch’.</p>
<ul>
<li>questions - question about the chapter</li>
<li>key concepts - summarized key concepts of the chapter</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Links
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Homepage: <a href="https://www.fast.ai/">fastai hompage</a></li>
<li>Online Book: <a href="https://course.fast.ai/Resources/book.html">fastai online book</a></li>
<li>Author: <a href="https://jeremy.fast.ai/">jermey howard</a></li>
<li>Author: <a href="https://sgugger.github.io/">sylvain gugger</a></li>
</ul>
</div>
</div>
</section>
<section id="questions" class="level1">
<h1>Questions</h1>
<p>Questions about the chapter.</p>
<p><a href="../../posts/2023-08-14_your_deep_learning_journey/subsite/your_deep_learning_journey_questions.html">Questions - Chapter 1 - Your deep learning journey</a></p>
</section>
<section id="code" class="level1">
<h1>Code</h1>
<p>Code from this chapter.</p>
<p><a href="https://github.com/xjanfcc/fastai/blob/master/book/chapter_1_your_deep_learning_practice/cats_and_dogs.ipynb">Code - Chapter 1 - Your deep learning journey - Is this a cat</a></p>
<p><a href="https://github.com/xjanfcc/fastai/blob/master/course/part_1-1_getting_started/is_it_a_bird.ipynb">Code - Course 1-1 - Getting Started - Is it a bird</a></p>
</section>
<section id="key-concepts" class="level1">
<h1>Key Concepts</h1>
<p>Summarized key concepts ot this chapter.</p>
<section id="what-is-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-is-machine-learning">What is machine learning</h2>
<p>The idea is instead of telling the computer the exact steps required to solve a problem, show it examples of the problem to solve, and let it figure out how to solve it itself.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-08-14_your_deep_learning_journey/maschine_learning.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">training a machine learning model - fastai - 2023</figcaption>
</figure>
</div>
<ul>
<li>weight assignment</li>
<li>automatic means of testing the effectiveness</li>
<li>current weight assignment in terms of actual performance</li>
<li>mechanism for altering the weight assignment so as to maximize the performance</li>
</ul>
</section>
<section id="what-is-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-is-deep-learning">What is deep learning</h2>
<p>Deep learning is specialty within machine learning that uses neural networks with multiple layers.</p>
</section>
<section id="why-are-neural-network-great-for-machine-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="why-are-neural-network-great-for-machine-deep-learning">Why are neural network great for machine / deep learning</h2>
<ul>
<li>If you regard a neural network as a mathematical function, it turns out to be function that ist extremely flexible depending on its weights.</li>
<li>A mathematical proof called the universal approximation theorem shows that this function can solve any problem to any level of accuracy.</li>
<li>In neural network we can use stochastic gradient descent (SGD).</li>
<li>To determine the actual performance we can define our models performance as its accuracy at predicting the correct answers.</li>
</ul>
</section>
<section id="modern-deep-learning-loop-and-jargon" class="level2">
<h2 class="anchored" data-anchor-id="modern-deep-learning-loop-and-jargon">Modern Deep Learning Loop and Jargon</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-08-14_your_deep_learning_journey/modern_deep_learning_loop.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">modern deep learning loop - fastai - 2023</figcaption>
</figure>
</div>
<ul>
<li><b>Architecture</b> The template of the model that we trying to fit, the actual mathematical function that we’re passing the input data and parameters to.</li>
<li><b>Model</b> The combination of the architecture with a particular set of parameters.</li>
<li><b>Label</b> The data that we trying to predict.</li>
<li><b>Parameters</b> The values in the model that change what task it can do and that are updated through model training</li>
<li><b>Predictions</b> The results of the model are called predictions. The predictions are calculated from the independent variable, which is the data not including the labels.</li>
<li><b>Loss</b> Loss ist the measurement of the performance. The loss depends not only on the predictions, but also on the correct labels.</li>
<li><b>Fit / Train</b> Update the parameters of the model such that the predictions of the model using the input data match the target labels.</li>
<li><b>Epoch</b> One complete pass through the input data (training set)</li>
</ul>
</section>
<section id="limitations-inherent-to-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="limitations-inherent-to-machine-learning">Limitations Inherent to Machine Learning</h2>
<ul>
<li>A model cannot be created without data.</li>
<li>A model can learn to operate on only the patterns seen in the input data used to train it.</li>
<li>This learning approach creates only predictions, not recommended actions.</li>
<li>It’s not enough to just have examples of input data, we need labels for that data too.</li>
</ul>
</section>
<section id="classification-and-regression" class="level2">
<h2 class="anchored" data-anchor-id="classification-and-regression">Classification and Regression</h2>
<ul>
<li><b>Classification</b> A classification model is one that attempts to predict a class, or category. That is, it’s predicting from a number of discrete possibilities.</li>
<li><b>Regression</b> A regression model is one that attempts to predict one or more numeric quantities, such as a temperature or a location.</li>
</ul>
</section>
<section id="what-is-overfitting" class="level2">
<h2 class="anchored" data-anchor-id="what-is-overfitting">What is Overfitting</h2>
<p>Overfitting is the single most important and challenging issue when training for all machine learning. Training a model in such a way that it remembers specific features of the input data, rather than generalizing well to data not seen during training.</p>
</section>
<section id="training-set-validation-sets-and-test-sets" class="level2">
<h2 class="anchored" data-anchor-id="training-set-validation-sets-and-test-sets">Training Set, Validation Sets and Test Sets</h2>
<ul>
<li><b>Training set</b> The data used for fitting the model, does not include any data from the validation set. (If there is enough data 80% is used for training)</li>
<li><b>Validation set</b> A set of data held out from training, used only for measuring how good the model is. (If there is enough data 20% is used for validation)</li>
<li><b>Test set</b> As we hold the validation data back from the training process, we can hold back a test set data even from ourselves. It cannot be used to improve the model, it can only be used to evaluate the model at the very end. (Take out some data for testing and split the rest to 80% for training and 20% for validation)</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For decision makers it is important to unsure to rally understand what a test and validation set is. For example you should never give out all the data to an external vender. Always hold some test data (test set) for your own validation of the final model.</p>
</div>
</div>
</section>
<section id="what-is-a-cnn-convolutional-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-cnn-convolutional-neural-network">What is a CNN (Convolutional neural network)</h2>
<p>Convolutional neural network, a type of neural network that works particularly well for computer vision tasks.</p>
</section>
<section id="pertrained-model-and-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="pertrained-model-and-fine-tuning">Pertrained model and Fine-tuning</h2>
<p><b>Pretrained model</b> A pretrained model has weights already been trained on some other dataset. You should nearly always use a pretrained model, because it means the your model, before you’ve even shown it any of your data, is already very capable. For instance. parts of pretrained models will handle edge, gradient, and color detection. which are needed for many tasks.</p>
<p><b>Transfer learning</b> Using a pretrained model for a task different to what it was originally trained for.</p>
<p><b>Fine-tuning</b> A transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task that used for pretraining.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Using a pretrained model is the most important method we have to allow us to train more accurate models, more quickly, with less data, and less time and money.</p>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>fastai</category>
  <category>deeplearning</category>
  <category>self-study</category>
  <guid>https://janf.cc/posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html</guid>
  <pubDate>Sun, 13 Aug 2023 22:00:00 GMT</pubDate>
  <media:content url="https://janf.cc/posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>hello world</title>
  <dc:creator>janf </dc:creator>
  <link>https://janf.cc/posts/2023-06-30_welcome/welcome_post.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://janf.cc/posts/2023-06-30_welcome/welcome_thumbnail.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">flora - janf - 2020</figcaption>
</figure>
</div>
<section id="this-is-the-first-post-on-this-blog.-seavas" class="level1">
<h1>This is the first post on this blog. Seavas!</h1>
<p>Hello, I’m <a href="../../about.html">Jan F.</a> from west austria 🇦🇹 . <br> I like to learn and create new things. Here i take notes about these processes or outcomes ✌️</p>


</section>

 ]]></description>
  <category>social</category>
  <guid>https://janf.cc/posts/2023-06-30_welcome/welcome_post.html</guid>
  <pubDate>Thu, 29 Jun 2023 22:00:00 GMT</pubDate>
  <media:content url="https://janf.cc/posts/2023-06-30_welcome/welcome_thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
