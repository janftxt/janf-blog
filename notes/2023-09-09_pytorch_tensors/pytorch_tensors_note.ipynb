{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'pytorch tensors'\n",
    "description: 'pytorch tensors'\n",
    "author: 'janf'\n",
    "date: '2023-09-09'\n",
    "date-format: iso\n",
    "categories: [notes]\n",
    "toc: true\n",
    "execute: \n",
    "  enabled: false\n",
    "format:\n",
    "  html:\n",
    "    code-copy: true\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Tensors\n",
    "\n",
    "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of model, as well as the model's parameters. Tensors are similar to NumPy's arrays, expect that tensors can run on GPU or other hardware.\n",
    "\n",
    "[PyTorch Tensor](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "[Introduction to PyTorch Tensors](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factory Method to create Tensor\n",
    "The simplest way to create a tensor is with the torch.empty() call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[3.2007e-36, 0.0000e+00, 2.8482e-36, 0.0000e+00],\n",
      "        [1.1210e-43, 0.0000e+00, 8.9683e-44, 0.0000e+00],\n",
      "        [2.8872e-36, 0.0000e+00, 5.6052e-45, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3,4)\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this creates a tensor using on of the numerous factory methods attached to the **torch** module.\n",
    "- the tensor itself is 2-dimensional, having 3 rows and 4 columns.\n",
    "- the type of the object returned is **torch.Tensor**, which is an alias for **torch.FloatTensor**, by default PyTorch tensors are 32-bit floating point numbers.\n",
    "- there are some random-looking values in the tensor. The **torch.empty()** call allocates memory for the tensor, but does not initialize it with any values -  so what your're seeing is whatever was in memory at the time of allocation.\n",
    "\n",
    "If you want to initialize the tensor with some vales. Common cases are all zeros, all ones, or random values. The torch module provides factory methods for alle of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.3699, 0.5704, 0.4876],\n",
      "        [0.3391, 0.1535, 0.0455]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor full of zeros\n",
    "zeros = torch.zeros(2,3)\n",
    "print(zeros)\n",
    "\n",
    "# create a tensor full of ones\n",
    "ones = torch.ones(2,3)\n",
    "print(ones)\n",
    "\n",
    "# create a tensor full of random values\n",
    "torch.manual_seed(1779)\n",
    "random = torch.rand(2,3)\n",
    "print(random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology about tensors and thier number of dimensions\n",
    "\n",
    "- You will sometimes see a **1-dimensional tensor** called a **vector**.\n",
    "- A **2-dimensional tensor** is often referred as a **matrix**.\n",
    "- Anything with **more than two dimensions** is generally just called a **tensor**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensor and Seeding\n",
    "\n",
    "Sometimes you want the same random values for reproducibility. Manually setting your random number generator's seed fixes the random outputs to get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2,3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2,3)\n",
    "print(random2)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2,3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2,3)\n",
    "print(random4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you should see above is that **random1** and **random3** carry identical values, as do **random2** and **random4**. Manually resetting the seed gives the same results when you compute the things again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Shapes\n",
    "\n",
    "Often when you are performing operations on two or more tensors, they will need to be of the same shape - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the **torch.*_like()** methodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[2.8892e-36, 0.0000e+00, 2.7489e-36],\n",
      "         [0.0000e+00, 1.4013e-45, 0.0000e+00]],\n",
      "\n",
      "        [[1.4013e-45, 0.0000e+00, 1.4013e-45],\n",
      "         [0.0000e+00, 1.4013e-45, 0.0000e+00]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[2.9069e-36, 0.0000e+00, 2.7489e-36],\n",
      "         [0.0000e+00, 1.4013e-45, 0.0000e+00]],\n",
      "\n",
      "        [[1.4013e-45, 0.0000e+00, 1.4013e-45],\n",
      "         [0.0000e+00, 1.4013e-45, 0.0000e+00]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.6128, 0.1519, 0.0453],\n",
      "         [0.5035, 0.9978, 0.3884]],\n",
      "\n",
      "        [[0.6929, 0.1703, 0.1384],\n",
      "         [0.4759, 0.7481, 0.0361]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2,2,3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "empty_like_x = torch.empty_like(x)\n",
    "print(empty_like_x.shape)\n",
    "print(empty_like_x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "print(zeros_like_x.shape)\n",
    "print(zeros_like_x)\n",
    "\n",
    "ones_like_x = torch.ones_like(x)\n",
    "print(ones_like_x.shape)\n",
    "print(ones_like_x)\n",
    "\n",
    "rand_like_x = torch.rand_like(x)\n",
    "print(rand_like_x.shape)\n",
    "print(rand_like_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first new thing in the code cell above is the use of the **.shape** property on a tensor. This property contains a list of the extent of each dimension of a tensor - in our case, **x** is a three-dimensional tensor with shape 2x2x3. Then we created new tensor's with **.empty_like(), .zeros_like(), .ones_like(), .rand_like()** methods. With **.shape** we can verify that **x** has the same size as our new tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Tensor with specific data directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[3.1410, 2.7890],\n",
      "        [1.2340, 4.9230]])\n",
      "torch.Size([10])\n",
      "tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([2, 3])\n",
      "tensor([[2, 4, 6],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "some_constants = torch.tensor([[3.141, 2.789], [1.234, 4.923]])\n",
    "print(some_constants.shape)\n",
    "print(some_constants)\n",
    "\n",
    "some_intergers = torch.tensor((2,3,4,5,6,7,8,9,10,11))\n",
    "print(some_intergers.shape)\n",
    "print(some_intergers)\n",
    "\n",
    "more_intergers = torch.tensor(((2,4,6), [3,6,9]))\n",
    "print(more_intergers.shape)\n",
    "print(more_intergers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **torch.tensor()** is the most straightforward way to create a tensor if your already have data in a Python tuple or list. Nesting will result in multi-dimensional tensor.\n",
    "\n",
    "Note: **torch.tensor()** creates a copy of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Tensor Shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider tensor shapes as the number of lists that a dimension holds. For instance, a tensor shaped (4,4,2) will have four elements, which all contain 4 elements, which in turn have 2 elements.\n",
    "\n",
    "1. The first holds 4 elements.\n",
    "2. The second holds 4 elements.\n",
    "3. The third dimension holds 2 elements.\n",
    "\n",
    "![torch.Size([4,4,2\"])](441.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 2])\n",
      "tensor([[[ 1.4934e-38,  0.0000e+00],\n",
      "         [ 2.7444e-36,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4013e-45,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 1.5835e-43,  0.0000e+00]],\n",
      "\n",
      "        [[-1.2993e+10,  4.5653e-41],\n",
      "         [ 2.7445e-36,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4013e-45,  0.0000e+00]],\n",
      "\n",
      "        [[ 9.1844e-41,  1.1551e-40],\n",
      "         [ 1.1481e-41,  2.0739e-43],\n",
      "         [ 8.9683e-44,  0.0000e+00],\n",
      "         [ 6.7262e-44,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "tensor442 = torch.empty(4,4,2)\n",
    "print(tensor442.shape)\n",
    "print(tensor442)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structures in tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create tensor:\n",
      "tensor([1.])\n",
      "create tensor:\n",
      "tensor([1.])\n",
      "get value 1:\n",
      "tensor(1.)\n",
      "shape:\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# [x]\n",
    "# ----------------------- \n",
    "# scalar\n",
    "# 0D (zero dimension)\n",
    "print('create tensor:')\n",
    "d0 = torch.ones(1)\n",
    "print(d0)\n",
    "\n",
    "print('create tensor:')\n",
    "d0 = torch.tensor([1.])\n",
    "print(d0)\n",
    "\n",
    "print('get value 1:')\n",
    "print(d0[0])\n",
    "\n",
    "print('shape:')\n",
    "print(d0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create tensor:\n",
      "tensor([1., 1., 1.])\n",
      "create tensor:\n",
      "tensor([1., 2., 3.])\n",
      "get value 3:\n",
      "tensor(3.)\n",
      "shape:\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# [x]\n",
    "# [x]\n",
    "# [x]\n",
    "# -----------------------\n",
    "# vector\n",
    "# 1D (one dimension)\n",
    "print('create tensor:')\n",
    "d1 = torch.ones(3)\n",
    "print(d1)\n",
    "\n",
    "print('create tensor:')\n",
    "d1 = torch.tensor([1.,2.,3.])\n",
    "print(d1)\n",
    "\n",
    "print('get value 3:')\n",
    "print(d1[2])\n",
    "\n",
    "print('shape:')\n",
    "print(d1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create tensor:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "create tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "get value 4:\n",
      "tensor(4.)\n",
      "shape:\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# [x x x]\n",
    "# [x x x]\n",
    "# [x x x]\n",
    "# -----------------------\n",
    "# matrix\n",
    "# 2D (two dimension)\n",
    "print('create tensor:')\n",
    "d2 = torch.ones(3,3)\n",
    "print(d2)\n",
    "\n",
    "print('create tensor:')\n",
    "d2 = torch.tensor([[1.,2.,3.],[4.,5.,6.],[7.,8.,9.]])\n",
    "print(d2)\n",
    "\n",
    "print('get value 4:')\n",
    "print(d2[1,0])\n",
    "\n",
    "print('shape:')\n",
    "print(d2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x x x] [x x x] [x x x]\n",
    "# [x x x] [x x x] [x x x]\n",
    "# [x x x] [x x x] [x x x]\n",
    "# -----------------------\n",
    "# tensor\n",
    "# 3D (3 dimension)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension > 3\n",
    "# -----------------------\n",
    "# tensor\n",
    "# XD (x > 3 dimension)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the datatype of a tensor is possible a couple of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[ 0.9956,  1.4148,  5.8364],\n",
      "        [11.2406, 11.2083, 11.6692]], dtype=torch.float64)\n",
      "tensor([[ 0,  1,  5],\n",
      "        [11, 11, 11]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2,3), dtype=torch.int16)\n",
    "print(a)\n",
    "\n",
    "b = torch.rand((2,3), dtype=torch.float64) * 20\n",
    "print(b)\n",
    "\n",
    "c = b.to(torch.int32)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to set underlying data type of a tensor is with an optional argument at creation time. At \"a\" we set **dtype=torch.int16**. Printing **a** shows that the data is 1 rather than 1. (1 int, 1. float)\n",
    "\n",
    "Another thing to notice by printing out a tensor it also shows the specified dtype.\n",
    "\n",
    "Another way to set the datatype is with the **.to()** method. In the cell above, we create a random floating point tensor **b** and den converted b to a 32-bit integer in **c**.\n",
    "\n",
    "PyTorch datatypes:\n",
    "\n",
    "- torch.bool\n",
    "- torch.int8\n",
    "- torch.uint8\n",
    "- torch.int16\n",
    "- torch.int32\n",
    "- torch.int64\n",
    "- torch.half\n",
    "- torch.float\n",
    "- torch.double\n",
    "- torch.bfloat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math & Logic with Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic arithmetic with tensors and how tensor interact with simple scalars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]])\n",
      "tensor([[1.4142, 1.4142],\n",
      "        [1.4142, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.zeros(2,2) + 1\n",
    "twos = torch.ones(2,2) * 2\n",
    "threes = (torch.ones(2,2) * 7 - 1) / 2\n",
    "fours = twos ** 2\n",
    "sqrt2s = twos ** 0.5\n",
    "\n",
    "print(ones)\n",
    "print(twos)\n",
    "print(threes)\n",
    "print(fours)\n",
    "print(sqrt2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arithmetic operations between tensors and scalars, such as addition, subtraction, multiplication, division, and exponentiation are distributed over every element of the tensor.\n",
    "\n",
    "Operation between tow tensors also behave like you'd intuitively expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.],\n",
      "        [ 8., 16.]])\n",
      "tensor([[5., 5.],\n",
      "        [5., 5.]])\n",
      "tensor([[12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "powers2 = twos ** torch.tensor([[1,2], [3,4]])\n",
    "print(powers2)\n",
    "\n",
    "fives = ones + fours\n",
    "print(fives)\n",
    "\n",
    "dozens = threes * fours\n",
    "print(dozens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that all of the tensors in the previous code cell were of identical shape. What happens when we try to perform a binary operation on tensor if dissimilar shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb Cell 38\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m3\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(a \u001b[39m*\u001b[39;49m b)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# The following throws a run-time error. This is intentional.\n",
    "\n",
    "a = torch.rand(2,3)\n",
    "b = torch.rand(3,2)\n",
    "\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general case, you cannot operate on tensors of different shape this way,even in a case like the call above, where the tensor have identical number of elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Brief: Tensor Broadcasting\n",
    "\n",
    "The exception to the same-shape rule is tensor broadcasting. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2024, 0.5731, 0.7191, 0.4067],\n",
      "        [0.7301, 0.6276, 0.7357, 0.0381]])\n",
      "tensor([[0.4049, 1.1461, 1.4382, 0.8134],\n",
      "        [1.4602, 1.2551, 1.4715, 0.0762]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "rand = torch.rand(2,4)\n",
    "doubled = rand * (torch.ones(1,4)*2)\n",
    "\n",
    "print(rand)\n",
    "print(doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it we get to multiply a 2x4 tensor by a 1x4 tensor?\n",
    "\n",
    "Broadcasting is a way to perform an operation between tensors that have similarities in their shapes. In the example above, the one-row, four-column tensor is multiplied by both rows of the two-row, four-column tensor.\n",
    "\n",
    "![Pytorch Broadcasting](broadcasting.jpg)\n",
    "\n",
    "This is an important operation in Deep Learning. The common example is multiplying a tensor of learning weights by a batch of input tensors, applying the operation to each instance in the batch separately, and returning a tensor of identical shape - just like our (2,4) * (1,4) example above returned a tensor of shape (2,4).\n",
    "\n",
    "The rules of broadcasting are:\n",
    "\n",
    "- Each tensor must have at least one dimension - no empty tensors.\n",
    "- Comparing the dimension sizes of the tow tensors, going from last to first:\n",
    "    - Each dimension must be equal of\n",
    "    - One of the dimension must be of size 1, or\n",
    "    - Dimension does not exist in one of the tensors\n",
    "\n",
    "Tensors of identical shape, of course are trivially \"broadcastable\", as you saw earlier.\n",
    "\n",
    "Here are some examples of situation that honor the above rules and allow broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(     4,  3,  2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0381, 0.2138],\n",
      "         [0.5395, 0.3686],\n",
      "         [0.4007, 0.7220]],\n",
      "\n",
      "        [[0.0381, 0.2138],\n",
      "         [0.5395, 0.3686],\n",
      "         [0.4007, 0.7220]],\n",
      "\n",
      "        [[0.0381, 0.2138],\n",
      "         [0.5395, 0.3686],\n",
      "         [0.4007, 0.7220]],\n",
      "\n",
      "        [[0.0381, 0.2138],\n",
      "         [0.5395, 0.3686],\n",
      "         [0.4007, 0.7220]]])\n"
     ]
    }
   ],
   "source": [
    "b = a * torch.rand(     3,  2) # 3rd & 2nd dims identical to a, dim 1 absent\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8217, 0.8217],\n",
      "         [0.2612, 0.2612],\n",
      "         [0.7375, 0.7375]],\n",
      "\n",
      "        [[0.8217, 0.8217],\n",
      "         [0.2612, 0.2612],\n",
      "         [0.7375, 0.7375]],\n",
      "\n",
      "        [[0.8217, 0.8217],\n",
      "         [0.2612, 0.2612],\n",
      "         [0.7375, 0.7375]],\n",
      "\n",
      "        [[0.8217, 0.8217],\n",
      "         [0.2612, 0.2612],\n",
      "         [0.7375, 0.7375]]])\n"
     ]
    }
   ],
   "source": [
    "c = a * torch.rand(     3,  1) # 3rd dim = 1, 2nd dim identical to a\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8328, 0.8444],\n",
      "         [0.8328, 0.8444],\n",
      "         [0.8328, 0.8444]],\n",
      "\n",
      "        [[0.8328, 0.8444],\n",
      "         [0.8328, 0.8444],\n",
      "         [0.8328, 0.8444]],\n",
      "\n",
      "        [[0.8328, 0.8444],\n",
      "         [0.8328, 0.8444],\n",
      "         [0.8328, 0.8444]],\n",
      "\n",
      "        [[0.8328, 0.8444],\n",
      "         [0.8328, 0.8444],\n",
      "         [0.8328, 0.8444]]])\n"
     ]
    }
   ],
   "source": [
    "d = a * torch.rand(     1,  2) # 3rd dim identical to a, 2nd dim = 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look closely at the values of each tensor above:\n",
    "\n",
    "- The multiplication operation that created **b** was broadcast over every 'layer' of **a**.\n",
    "- For **c**, the operation was broadcast over ever layer and row of **a** - every 3-element column is identical.\n",
    "- For **d**, we switched it around - now every row is identical, across layers and columns.\n",
    "\n",
    "One example where broadcasting will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb Cell 42\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(     \u001b[39m4\u001b[39m,  \u001b[39m3\u001b[39m,  \u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m b \u001b[39m=\u001b[39m a \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49mrand(     \u001b[39m4\u001b[39;49m,  \u001b[39m3\u001b[39;49m)  \u001b[39m# dimension must match last-to-first\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m c \u001b[39m=\u001b[39m a \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mrand(     \u001b[39m2\u001b[39m,  \u001b[39m3\u001b[39m)  \u001b[39m# both 3rd & 2nd dims different\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jf/Development/quarto/janf-blog/notes/2023-09-09_pytorch_tensors/pytorch_tensors_note.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m d \u001b[39m=\u001b[39m a \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m0\u001b[39m,)          \u001b[39m# cant broadcast with an empty tensor\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "a = torch.ones(     4,  3,  2)\n",
    "\n",
    "b = a * torch.rand(     4,  3)  # dimension must match last-to-first\n",
    "\n",
    "c = a * torch.rand(     2,  3)  # both 3rd & 2nd dims different\n",
    "\n",
    "d = a * torch.rand(0,)          # cant broadcast with an empty tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Tensors Shpares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch-Numpy Bridge\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
