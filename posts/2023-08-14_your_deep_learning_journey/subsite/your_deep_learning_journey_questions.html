<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>janf - Questions - Chapter 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../images/janftxt_favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">janf</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../notes.html" rel="" target="">
 <span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/janftxt" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/janftxt" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Questions - Chapter 1</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Back to blog post
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="../../../posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html">fastai book chapter 1</a></p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Links
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Source: <a href="https://forums.fast.ai/t/fastbook-chapter-1-questionnaire-solutions-wiki/65647">Fastbook Chapter 1 questionnaire solutions (wiki)</a></li>
</ul>
</div>
</div>
<p><b> What is Deep Learning? </b></p>
<p>Deep learning is a computer technique to extract anf transform data for that it uses multiple layers of neural networks. The layers are trained by alogrithms that minimze thier accuracy. In this way, the network learn to perform a specified task.</p>
<p><b> Do you need these for Deep Learning?</b></p><b>
</b><ul><b>
<li><p>Lots of Math (True/False)</p></li>
<li><p>Lots of Data (True/False)</p></li>
<li><p>Lots of expensive computers (True/False)</p></li>
</b><li><b></b><p><b>A Phd (True/False) </b></p></li>
<li><p>Lots of Math (False)</p></li>
<li><p>Lots of Data (False)</p></li>
<li><p>Lots of expensive computers (False)</p></li>
<li><p>A Phd (False)</p></li>
</ul>
<p><b> Name five areas where deep learning is now the best tool in the world? </b></p>
<ul>
<li>Medicine
<ul>
<li>Cancer detection</li>
</ul></li>
<li>Security
<ul>
<li>Spam detection</li>
</ul></li>
<li>Computer vision
<ul>
<li>Classification of Images</li>
</ul></li>
<li>Playing Games
<ul>
<li>Chess, Go</li>
</ul></li>
<li>Natural language processing (NLP)
<ul>
<li>summerizing documents, classifying documents</li>
</ul></li>
</ul>
<p><b> What was the name of the first device that was based on the principle of the artificial neuron? </b></p>
<p>Mark 1-Perceptron.</p>
<p>Frank Rosenblatt further developed the artificial neuron to give it the ability to learn. Based on this he worked on building the first device that actually used these principles, the Mark ! Perceptron.</p>
<p><b> Based on the book of the same name, what are the requirements for parallel distrubted processing? </b></p>
<p>Based on the definition parallel distributed processing the requirements are: 1. A set of processing units 2. A stat of activation 3. An output function for each unit 4. A pattern of connectivity among units 5. A propagation rule for propagating pattern of activities through th network of conductivities. 6. An activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit. 7. A learning rule whereby patterns of connectivity are modified by experience. 8. An environment within which the system must operate.</p>
<p><b> What were the tow theoretical misunderstandings that held back the field of neural networks? </b></p>
<p>In 1969, Marvin Minsky an Seymour Papert demonstrated in their book, “Perceptrons”, that a single layer of artificial neurons cannot learn simple, critical mathematical functions like XOR logic gate. While they subsequently demonstrated in the same book that additional layers can solve this problem, only the first insight was recognizes, leading to the start of the first AI winter.</p>
<p>In the 1980’s models with tow layers were being explored. Theoretically, it is possible to approximate any mathematical function using two layers of artificial neurons. However, in practices, these networks were too big and too slow. While it was demonstrated that adding additional layers improved performance, this insight was not acknowledged, and the second AI winter began. In this past decade, with increased data availability, and improvements in computer hardware (both in CPU performance but more importantly in GPU performance), neural networks are finally living up to its potential.</p>
<p><b> What is a GPU? </b></p>
<p>A GPU is a Graphics Processing Unit. They were specializes processing units designed to accelerate graphics redndering for gaming. Thanks to their unique capability to efficiently parallelize massive distributed computational processes, GPUs have successfully been applied to applications beyond their original remit. These optimizations and capability’s allow us to run and train neural networks hundreds of times faster than a regular CPU.</p>
<p><b> Open a notebook and execute a cell containing: 1+1. What happens? </b></p>
<p>In Jupyter Notebook we can create code cells in an interactive manner. When we execute a cell containing some code, the code runs by Python and the output is displayed under the curren code cell.</p>
<p>Code Cell: 1+1 Output under der Code Cell: 2</p>
<p><b> Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen. </b></p>
<p>ToDo</p>
<p><b> Complete the Jupyter Notebook online appendix (https://oreil.ly9uPZe). </b></p>
<p>ToDo</p>
<p><b> Why is it hard to use traditional computer program to recognize images in a photo? </b></p>
<p>When creating a normal computer program think about some steps and translate them into code. As Example we can write an algorithm to sort a list. But for recognizing an image or object it is tricky. We as human subconsciously learned a lot of features defining one object from an other. It is very difficult to manually code these complex patterns of shapes, textures, colors, and other features to recognize different objects and images.</p>
<p><b> What did Samuel mean by “weight assignment”? </b></p>
<p>“weight assignment” refers to the current values of the model parameters. Arthur Samuel further mentions an “ automatic means of testing the effectiveness of any current weight assignment ” and a “ mechanism for altering the weight assignment so as to maximize the performance ”. This refers to the evaluation and training of the model in order to obtain a set of parameter values that maximizes model performance.</p>
<p><b> What term do we normally use in deep learning for what Samuel called “weights”? </b></p>
<p>Weights are also called parameters.</p>
<p><b> Draw a picture that summarizes Samuel`s view of a machine learning model. </b></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../maschine_learning.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">machine learning model</figcaption>
</figure>
</div>
<p><b> Why is it hard to understand why a deep learning model makes a particular prediction? </b></p>
<p>All kinds of machine learning models (including deep learning and traditional statical models) can be challenging to fully understand. Think of a linear regression model. Simply, we have some input variables/data that are multiplied by some weights, giving us an output. We can understand which variables are more important and which are less important based on their weights. A similar logic might apply for a small neural network with 1-3 layers. However, deep neural networks have hundreds, if not thousands, of layers. It is hard to determine which factors are important in determining the final output. The neurons in the network interact with each other, with the outputs of some neurons feeding into other neurons. Altogether, due to the complex nature of deep learning models, it is very difficult to understand why a neural network makes a given prediction.</p>
<p>However, in some cases, recent research has made it easier to better understand a neural network’s prediction. For example, as shown in this chapter, we can analyze the sets of weights and determine what kind of features activate the neurons. When applying CNNs to images, we can also see which parts of the images highly activate the model. We will see how we can make our models interpretable later in the book.</p>
<p><b> What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy? </b></p>
<p>If you regard a neural network as a mathematical function, it turns out to be a function which is extremely flexible depending on its weights. A mathematical proof called the universal approximation theorem shows that this function can solve any problem to any level of accuracy, in theory.</p>
<p><b> What do you need in order to train a model? </b></p>
<p>You need a architecture, a general template for how that kind of model works internally. For training/fitting the model you need data to specialize the general architecture. To define how well a model does on a single prediction. We need to define a loss function, which determines how good the model performs. Do determine the loss we need labeled data, data indicating what it represent.</p>
<p><b> How could a feedback loop impact the rollout of a predictive policing model? </b></p>
<p>In a predictive policing model, we might end up with a positive feedback loop, leading to a highly biased model with little predictive power. For example, we may want a model that would predict crimes, but we use information on arrests as a proxy . However, this data itself is slightly biased due to the biases in existing policing processes. Training with this data leads to a biased model. Law enforcement might use the model to determine where to focus police activity, increasing arrests in those areas. These additional arrests would be used in training future iterations of models, leading to an even more biased model. This cycle continues as a positive feedback loop.</p>
<p><b> Do we always have to use 224x224-pixel images with the cat recogintion? </b></p>
<p>No, This is the standard size for historical reasons (old pretrained models require this size exactly), but you can pass pretty much anything. If you increase the size, you’ll often get a model with better results (since it will be able to focus on more details), but at the price of speed and memory consumption; the opposite is true if you decrease the size.</p>
<p><b> What is the difference between classification and regression? </b></p>
<ul>
<li><b>Classification</b> A classification model is one that attempts to predict a class, or category. That is, it’s predicting from a number of discrete possibilities.</li>
<li><b>Regression</b> A regression model is one that attempts to predict one or more numeric quantities, such as a temperature or a location.</li>
</ul>
<p><b> What is a validation set? What is a test set? Why do we need them? </b></p>
<ul>
<li><b>Training set</b> The data used for fitting the model, does not include any data from the validation set. (If there is enough data 80% is used for training)</li>
<li><b>Validation set</b> A set of data held out from training, used only for measuring how good the model is. (If there is enough data 20% is used for validation)</li>
<li><b>Test set</b> As we hold the validation data back from the training process, we can hold back a test set data even from ourselves. It cannot be used to improve the model, it can only be used to evaluate the model at the very end. (Take out some data for testing and split the rest to 80% for training and 20% for validation)</li>
</ul>
<p><b> What will fastai do if you don’t provide a validation set? </b></p>
<p>It will automatically create a validation dataset if no validation set is provided. By default fastai takes out 20% that is held out is randomly.</p>
<p><b> Can we always use a random sample for a validation set? Why or why not? </b></p>
<p>A good validation or test set should be representative of new data you will see in the future. Sometimes this isn’t true if a random sample is used. For example, for times series data, selecting sets randomly does not make sense. Instead, defining different time periods for the train, validation, and test set is a better approach.</p>
<p><b> What is overfitting? Provide an example. </b></p>
<p>Overfitting is the single most important and challenging issue when training for all machine learning. Training a model in such a way that it remembers specific features of the input data, rather than generalizing well to data not seen during training.</p>
<p><b> What is a metic? How does it differ from loss? </b></p>
<p>The concept of a metric may remind you of loss, but there is an important distinction. The entire purpose of loss is to define a “measure of performance” that the training system can use to update weights automatically. In other words, a good choice for loss is a choice that is easy for stochastic gradient descent to use. But a metric is defined for human consumption, so a good metric is one that is easy for you to understand, and that hews as closely as possible to what you want the model to do. At times, you might decide that the loss function is a suitable metric, but that is not necessarily the case.</p>
<p><b> How can pretrained models help? </b></p>
<p>A model that has weights that have already been trained on some other dataset is called a pretrained model. You should nearly always use a pretrained model, because it means that your model, before you’ve even shown it any of your data, is already very capable. For instance, parts of pretrained models will handle edge, gradient, and color detection, which are needed for many tasks. Using pretrained models is the most important method we have to allow us to train more accurate models, more quickly, with less data, and less time and money.</p>
<p><b> What is the “head” of a model? </b></p>
<p>The head of a model is the part that is newly added to be specific to the new dataset. So the other layers which were not replaced where already trained for what the model war originally thought for.</p>
<p><b> What kinds of features do the early layers of a CNN find? How about the later layers? </b></p>
<p>The early layers learn simple features corners, edges, lines, circles. The later layers learn more advanced features like eyes, wheels, outlines of animals trees or humans.</p>
<p><b> Are image models useful only for photos? </b></p>
<p>Nope! Image models can be useful for other types of images like sketches, medical data, etc.</p>
<p>However, a lot of information can be represented as images . For example, a sound can be converted into a spectrogram, which is a visual interpretation of the audio. Time series (ex: financial data) can be converted to image by plotting on a graph. Even better, there are various transformations that generate images from time series, and have achieved good results for time series classification. There are many other examples, and by being creative, it may be possible to formulate your problem as an image classification problem, and use pretrained image models to obtain state-of-the-art results!</p>
<p><b> What is an architecture? </b></p>
<p>The architecture is the template or structure of the model we are trying to fit. It defines the mathematical model we are trying to fit.</p>
<p><b> What is segmantaion? </b></p>
<p>Creating a model that can recognize the content of every individual pixel in an image is called segmentation. The result is a segmentation (mask) for which parts of the image correspond to the given label.</p>
<p><b> What is y_range used for? When do we need is? </b></p>
<p>y_range is being used to limit the values predicted when our problem is focused on predicting a numeric value in a given range (ex: predicting movie ratings, range of 0.5-5).</p>
<p><b> What are “hyperparameters”? </b></p>
<p>Training models requires various other parameters that define how the model is trained. For example, we need to define how long we train for, or what the learning rate is used (how fast the model parameters are changed). These sorts of parameters are hyperparameters.</p>
<p><b> What’s the best way to avoid failures when using AI in an organization? </b></p>
<ol type="1">
<li>Make sure a training, validation, adn testing set is defined properly in order to evaluate the model in an appropriate manner.</li>
<li>Try out a simple baseline, which future models should hopefully beat. Or even this simple baseline may be enough in some cases.</li>
</ol>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>