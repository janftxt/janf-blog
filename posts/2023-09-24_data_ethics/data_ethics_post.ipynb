{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'data ethics'\n",
    "description: 'fastai book chapter 3'\n",
    "author: \"janf\"\n",
    "date: \"2023-09-24\"\n",
    "date-format: iso\n",
    "image: data_ethics_thumbnail.jpg\n",
    "categories: [fastai, deeplearning, self-study]\n",
    "toc: true\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fastai book chapter 3 - janf - 2023](data_ethics_thumbnail.jpg){fig-align=\"left\" width=50%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This my summary of chapter 3 from the book 'Deep Learning for Coders with fastai & PyTorch'.\n",
    "\n",
    " - questions - question about the chapter\n",
    " - key concepts - summarized key concepts of the chapter\n",
    "\n",
    "::: {.callout-note}\n",
    "## Links \n",
    "\n",
    "- Homepage: [fastai hompage](https://www.fast.ai/)\n",
    "- Online Book: [fastai online book](https://course.fast.ai/Resources/book.html)\n",
    "- Author: [jermey howard](https://jeremy.fast.ai/)\n",
    "- Author: [sylvain gugger](https://sgugger.github.io/)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "Questions about the chapter. \n",
    "\n",
    "[Questions - Chapter 3 - Data Ethics](subsite/data_ethics_questions.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "No code for this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Concepts\n",
    "\n",
    "Summarized key concepts ot this chapter.\n",
    "\n",
    "## Why do Data Ethics Matter\n",
    "\n",
    "Everybody who is training models needs to consider how their models will be used, and consider how to best ensure that they are used as positively as possible. There are things you can do. And if you don't do them things can go pretty badly. In general there are many negative societal consequences linked to AI an machine learning being observed today (bugs, flawed feedback loops, biases). It'not just a moral burden to consider sometimes there a legal burdens also. As example the first person who was jailed in the Volkswagen diesel scandal was the engineer not the manager. There is no final solution to ensure your work is used the right way. But with the right questions, you can at the very least ensure that the right issues are being considered. And you can so \"no\" to questionable pieces of work if their moral aspects don't align.\n",
    "\n",
    "## Topics in Data Ethics\n",
    "\n",
    "Data ethics is a big field. This summery doesn't cover everything. The following are relevant topics to consider:\n",
    "\n",
    "### Recourse and Accountability\n",
    "\n",
    "In a complex system, it is easy for no one person to feel responsible for outcomes. While this understandable, it does not lead to good results. To hinder big errors you need Recourse and Accountability. An additional reason why recourse is so necessary is that data often contains errors. Mechanism for audits and error correction are crucial and should be considered by by practitioners.\n",
    "\n",
    "### Feedback Loops\n",
    "\n",
    "Feedback loops describe how an algorithm can interact with its environment to make predictions that reinforce action taken in the real world, which lead to predictions even more pronounced in the sam direction. Part of this problem is the driving metric of the algorithm. An algorithm has a metric to optimize, it will do everything it can to optimize their result. This can lead to all kinds of edge cases, and humans interacting with a system will search for, find, and exploit thees edge cases and feedback loops for their advantage. This behavior of feedback loops and tendencies for optimization can happen. As practitioner you should keep that in your mind and either anticipate a feedback loop and take positive action to break it when it happens.\n",
    "\n",
    "### Bias\n",
    "\n",
    "Bias in machine learning can come from multiple sources. In this section we summarize the types of bias that are most helpful for machine learning projects.\n",
    "\n",
    "- <i>Historical bias</i>\n",
    "    - x\n",
    "- <i> Measurement bias</i>\n",
    "    - x\n",
    "- <i>Aggregation bias</i>\n",
    "    - x\n",
    "- <i>Representation bias</i>\n",
    "    - x\n",
    "\n",
    "<i>Addressing different types of bias</i>\n",
    "\n",
    "## Disinformation\n",
    "\n",
    "## Addressing Ethical Issues\n",
    "\n",
    "### Analyze a Project You Are Working On\n",
    "\n",
    "### Processes to Implement\n",
    "\n",
    "### The Power of Diversity\n",
    "\n",
    "### Fairness, Accountability, and Transparency\n",
    "\n",
    "## Regulation, Rights and Policy\n",
    "\n",
    "### Regulation\n",
    "\n",
    "### Rights and Policy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
