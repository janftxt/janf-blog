{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions - Chapter 4\n",
    "::: {.callout-warning}\n",
    "## Back to blog post\n",
    "[fastai book chapter 4](../under_the_hood_training_a_digit_classifier_post.ipynb)\n",
    ":::\n",
    "\n",
    "::: {.callout-note}\n",
    "## Links\n",
    "- Source: [Fastbook Chapter 4 questionnaire solutions (wiki)](https://forums.fast.ai/t/fastbook-chapter-3-questionnaire-solutions-wiki/68042)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "How is a grayscale image represented on a computer? How about a color image?\n",
    "</b>\n",
    "\n",
    "Images are represented by arrays with pixel values representing the content of the image. For greyscale images, a 2-dimentional array is used with the pixeles representing the grayscale values, with a range of 256 integers. A value of 0 would represent white and a value of 255 represent black, and different shades of greyscale in between. For color images, three color channels (red,green,blue) are typicall used, with a separate 256-range 2D array used for each channel. A pixel of 0 again represent white, with 255 representing solid red, green or blue. The 2D arrays from a final 3D array (rank 3 tensor) representing the color image.\n",
    "\n",
    "<b>\n",
    "How are the files an folders in the MNIST_SAMPLE dataset structured? Why?\n",
    "</b>\n",
    "\n",
    "There are two subfolders, train and valid, the former contains the data for modeling training, the latter contains the data for validating model performance after each training step. Evaluating the model on the validation set serves tow purposes: a.) to report a human interpretable metric such as accuracy (in contract to the often abstract loss functions used for training), b.) to facilitate the detection of overfitting by evaluating the model on da dataset it hasn't been trained on (in short, an overfitting model performs increasingly well on the training set but decreasingly so an the validation set). Of course, every practitioner could generate their own train/validation-split of the data. Public datasets are usually pre-split to simplifying comparing results between implementations/publications.\n",
    "\n",
    "<b>\n",
    "Explain how the \"pixel similarity\" approach to classifying digits works.\n",
    "</b>\n",
    "\n",
    "In the pixel similarity approach, we generate an archetype for each class we want to identify. In our case, we want to distinguish images of 3's from images of 7's. We define the archetypical 3 as the pixel-wise mean values of all 3's in the training set. Analog for the 7's. You can visualize the tow archetypes and see that they are in fact blurred version of the number they represent. In order to tell if previously unseen image is a 3 or a 7, we calculate its distance to the tow archetypes (here: mean pixel-wise absolute difference). We say the new images are a 3 if the distance to the archetypical 3 is lower that tow the archetypical 7.\n",
    "\n",
    "<b>\n",
    "What is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\n",
    "</b>\n",
    "\n",
    "List (arrays in other programming languages) are often generated using a for-loop. A list comprehension in Python is condensing the creation of list using a for-loop into a single expression. List comprehension will also  often include if clauses for filtering.\n",
    "\n",
    "```python\n",
    "lst_in = range(10)\n",
    "lst_out = [2*el for el in lst_in if el%2==1]\n",
    "```\n",
    "\n",
    "```python\n",
    "list = []\n",
    "for el in lst_in:\n",
    "    if el%2==1:\n",
    "        lst_out.append(2*el)\n",
    "        \n",
    "lst_out\n",
    "```\n",
    "\n",
    "<b>\n",
    "What is a rank-3 tensor?\n",
    "</b>\n",
    "\n",
    "x\n",
    "\n",
    "<b>\n",
    "What is the difference between tensor rank and shape? How do you get the rank from the shape?\n",
    "</b>\n",
    "\n",
    "x\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
