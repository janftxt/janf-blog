[
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensor_note.html",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensor_note.html",
    "title": "pytorch tensor cheatsheet",
    "section": "",
    "text": "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of model, as well as the model’s parameters. Tensors are similar to NumPy’s arrays, expect that tensors can run on GPU or other hardware.\nPyTorch Tensor\nIntroduction to PyTorch Tensors"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensor_note.html#what-are-tensors",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensor_note.html#what-are-tensors",
    "title": "pytorch tensor cheatsheet",
    "section": "",
    "text": "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of model, as well as the model’s parameters. Tensors are similar to NumPy’s arrays, expect that tensors can run on GPU or other hardware.\nPyTorch Tensor\nIntroduction to PyTorch Tensors"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensor_note.html#import-torch",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensor_note.html#import-torch",
    "title": "pytorch tensor cheatsheet",
    "section": "Import torch",
    "text": "Import torch\n\nimport torch"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensor_note.html#creating-tensors",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensor_note.html#creating-tensors",
    "title": "pytorch tensor cheatsheet",
    "section": "Creating Tensors",
    "text": "Creating Tensors\nWays to create a tensor.\n\nFactory Method\nCreating an empty tensor. torch.empty()\n\n# creating a tensor with 2-dimensions, 3 rows and 4 columns.\nx = torch.empty(3,4)\n# by default tenors are 32-bit gloating point numbers.\n# torch.empty() allocates memory for the tensor but does not initialize it with any values\nprint(x)\n\ntensor([[4.4510e+31, 4.5797e-41, 4.2956e+31, 4.5797e-41],\n        [4.4525e+31, 4.5797e-41, 4.3583e+31, 4.5797e-41],\n        [4.4433e+31, 4.5797e-41, 4.4434e+31, 4.5797e-41]])\n\n\nCreating a tensor full of zeros. torch.zeros()\n\n# creating a tensor with 2-dimensions, 2 rows and 3 columns.\nx = torch.zeros(2,3)\nprint(x)\n\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n\n\nCreating a tensor full of ones. torch.ones()\n\n# creating a tensor with 2-dimensions, 3 rows and 1 column.\nx = torch.ones(3,1)\nprint(x)\n\ntensor([[1.],\n        [1.],\n        [1.]])\n\n\nCreating a tenor full of random values. torch.rand()\n\ntorch.manual_seed(187)\n# creating a tensor with 2-dimension, 2 rows and 3 columns.\nrandom = torch.rand(2,3)\nprint(random)\n\ntensor([[0.5305, 0.9925, 0.7754],\n        [0.9989, 0.3047, 0.9887]])\n\n\n\n\nCreating a tensor with specific data directly\ntorch.tensor() is the way to create a tenors if you have a Python tuple or list. Is creates a copy of the data as tensor.\n\nx = torch.tensor(([1,2,3],[4,5,6]))\nprint(x.shape)\nprint(x)\n\ntorch.Size([2, 3])\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\n\nRandom tensor and seeding\ntorch.manual_seed() sets the random seed to fixes the random outputs.\ntorch.rand() creates a random tensor.\n\ntorch.manual_seed(187)\nrandom = torch.rand(5,5)\nprint(random)\n\ntensor([[0.5305, 0.9925, 0.7754, 0.9989, 0.3047],\n        [0.9887, 0.3299, 0.2694, 0.5281, 0.8815],\n        [0.5275, 0.7802, 0.9964, 0.1060, 0.5047],\n        [0.6960, 0.1014, 0.8651, 0.9504, 0.7015],\n        [0.2917, 0.7787, 0.3808, 0.2624, 0.6519]])\n\n\n\n\nCreating tensor with the shape like\nCreating a tensor having the same number dimensions and the same number of cells in each dimension. - torch.empty_like() - torch.zeros_like() - torch.ones_like() - torch.rand_like()\n\nx = torch.empty(2,2,3)\nprint(x)\n\nzeros_like_x = torch.zeros_like(x)\nprint(zeros_like_x)\n\ntensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 1.0754e-35, 0.0000e+00]],\n\n        [[3.5508e-36, 0.0000e+00, 4.4087e+31],\n         [4.5797e-41, 1.4013e-45, 0.0000e+00]]])\ntensor([[[0., 0., 0.],\n         [0., 0., 0.]],\n\n        [[0., 0., 0.],\n         [0., 0., 0.]]])\n\n\n\n\nTerminology about tensors and thier number of dimensions\n\n0-dimensional tensor is called a scalar\n1-dimensional tensor is called a vector\n2-dimensional tensor is called a matrix\n3-dimensional or more tensor is called a tensor\n\n\nd0 = torch.ones(1)\nprint('scalar (0-dim)')\nprint(d0)\nprint('\\n')\n\nd1 = torch.ones(1,4)\nprint('vector 1-dim')\nprint(d1)\nprint('\\n')\n\n\nd2 = torch.ones(3,3)\nprint('matrix 2-dim')\nprint(d2)\nprint('\\n')\n\nd3 = torch.ones(4,4,4)\nprint('tensor 3-dim or more')\nprint(d3)\n\nscalar (0-dim)\ntensor([1.])\n\n\nvector 1-dim\ntensor([[1., 1., 1., 1.]])\n\n\nmatrix 2-dim\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])\n\n\ntensor 3-dim or more\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\n\n\n.shape property gives list of the extant of each dimension\n\nx = torch.zeros(2,1)\nx.shape\n\ntorch.Size([2, 1])\n\n\n\n\nTensor data types\nOne way to set the data type of a tensor is with an optional argument at creation.\nYou can see the specified dtype by printing the tensor.\n\na = torch.ones((2,3), dtype=torch.int16)\nprint(a)\n\ntensor([[1, 1, 1],\n        [1, 1, 1]], dtype=torch.int16)\n\n\nAnother way to set the datatype is with the .to() method. It converts a float64 and creates a int32 tensor.\n\na = torch.ones((2,3), dtype=torch.float64)\nprint(a)\n\nb = a.to(torch.int32)\nprint(b)\n\ntensor([[1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\ntensor([[1, 1, 1],\n        [1, 1, 1]], dtype=torch.int32)\n\n\nPyTorch datatypes:\n\ntorch.bool\ntorch.int8\ntorch.uint8\ntorch.int16\ntorch.int32\ntorch.int64\ntorch.half\ntorch.float\ntorch.double\ntorch.bfloat"
  },
  {
    "objectID": "notes/2023-06-30_anaconda _cheatsheet/anaconda_cheatsheet_note.html",
    "href": "notes/2023-06-30_anaconda _cheatsheet/anaconda_cheatsheet_note.html",
    "title": "anaconda cheatsheet",
    "section": "",
    "text": "Anaconda is a distribution of the Python for sientific computing (data sience, machine learning applications, large-scale data processing, predictive analytics, etc.), that aims to simplify package management and deployment.\nConda Documentation\nAnaconda (Python distribution)\n\n\n\n\nconda env list\n\n\n\nconda create --name ENV_NAME python=x.x\n\n\n\nconda enc create --file=environment.yml\n\n\n\nsource activate ENV_Name\nsource deactivate\n\n\n\nconda env remove --name ENV_NAME\n\n\n\nconda env export &gt; environment.yml\n\n\n\nconda create --clone ENV_NAME --name NEW_ENV_NAME\n\n\n\n\n\n\nconda search PACKAGE_NAME\n\n\n\nconda install PACKAGE_NAME\nconda install -c CHANNEL_NAME PACKAGE_NAME\n\n\n\nconda update PACKAGE_NAME\n\n\n\nconda list\n\n\n\n\n\n\nconda config --show channels\n\n\n\nconda config --aa channels CHANNEL_NAME\n\n\n\n\n\n\nconda info\n\n\n\nconda update conda"
  },
  {
    "objectID": "notes/2023-06-30_anaconda _cheatsheet/anaconda_cheatsheet_note.html#what-is-anaconda",
    "href": "notes/2023-06-30_anaconda _cheatsheet/anaconda_cheatsheet_note.html#what-is-anaconda",
    "title": "anaconda cheatsheet",
    "section": "",
    "text": "Anaconda is a distribution of the Python for sientific computing (data sience, machine learning applications, large-scale data processing, predictive analytics, etc.), that aims to simplify package management and deployment.\nConda Documentation\nAnaconda (Python distribution)\n\n\n\n\nconda env list\n\n\n\nconda create --name ENV_NAME python=x.x\n\n\n\nconda enc create --file=environment.yml\n\n\n\nsource activate ENV_Name\nsource deactivate\n\n\n\nconda env remove --name ENV_NAME\n\n\n\nconda env export &gt; environment.yml\n\n\n\nconda create --clone ENV_NAME --name NEW_ENV_NAME\n\n\n\n\n\n\nconda search PACKAGE_NAME\n\n\n\nconda install PACKAGE_NAME\nconda install -c CHANNEL_NAME PACKAGE_NAME\n\n\n\nconda update PACKAGE_NAME\n\n\n\nconda list\n\n\n\n\n\n\nconda config --show channels\n\n\n\nconda config --aa channels CHANNEL_NAME\n\n\n\n\n\n\nconda info\n\n\n\nconda update conda"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nfrom model to production\n\n\n\n\n\nfastai book chapter 2\n\n\n\n\n\n\n2023-08-18\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\nyour deep learning journey\n\n\n\n\n\nfastai book chapter 1\n\n\n\n\n\n\n2023-08-14\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\nhello world\n\n\n\n\n\nThe first post on this blog\n\n\n\n\n\n\n2023-06-30\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-08-18_from_model_to_production/subsite/from_model_to_production_questions.html",
    "href": "posts/2023-08-18_from_model_to_production/subsite/from_model_to_production_questions.html",
    "title": "Questions - Chapter 2",
    "section": "",
    "text": "Back to blog post\n\n\n\nfastai book chapter 2\n\n\n\n\n\n\n\n\nLinks\n\n\n\n\nSource: Fastbook Chapter 2 questionnaire solutions (wiki)\n\n\n\n Where do text models currently have major deficiency? \nCurrently deep learning is not good at generating correct responses! We don’t have a reliable way to, for instance, combine a knowledge base of medical information with a deep learning model for generating medically correct natural language responses. This can be very dangerous, as the layman may not be able to evaluate the factual accuracy of the generated text.\n What are possible negative societal implications of text generation models? \nA negative societal concern is that context-appropriate, highly compelling responses on social media could be used at massive scale, to spread disinformation, create unrest and encourage conflict.\nModels reinforce bias (like gender bias, racial bias) in training data and create a vicious cycle of biased outputs.\n In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process? \nOne alternative is to use an entirely manual process, with your deep learning model approach running in parallel but not being used directly to drive any actions. The humans involved in the manual process should look at the deep learning output and check whether they make sense.\n What kind of tabular data is deep learning particularly good at? \nIt great for analyzing time series and tabular data. Deep learning is also great at increasing columns containing neutral language and high categorical columns.\n What’s a key downside of directly using a deep learning model for recommendation systems? \nAlmost all machine learning approaches have the downside that they tell you only which product a particular user might like, rather than what recommendations would be helpful for a user. For example, if a user is familiar with other books from the same author, it isn’t helpful to recommend those products even though the user bought the author’s book. Or, recommending products a user may have already purchased.\n What are the steps of the Drivetrain Approach? \n\nDefine an objective\nUnderstand the levers: what inputs can you control?\nWhat data can you collect?\nmodel the levers in order to understand how they affect the objective.\n\nThe basic idea is to start with considering your objective, than think about what actions you can tak to meet that objective, then think about what actions you can take to meet that objective and what data you have (or can acquire) than can help, and then build a model that you can use to determine tha best actions to take to get the best results in terms of your objective.\n Create an image recognition model using data you curate, and deploy, it on the web. \nTodo. Watch Lesson 2 for help.\n What is Dataloaders? \n\nA DataLoader doesn’t care about preparing data, it expects the data ready to go and only cares about how to load the data (e.g. whether in parallel or in a single process) as well as feeding the data to the model in batches (i.e. batch size)\nA DataLoaders is a thin wrapper for more than one DataLoader\n\n What four things do we need to tell fastai to create DataLoaders? \n\nwhat kinds of data we working with\nhow to get the list of items\nhow to label these items\nhow to create the validation set\n\n What does the splitter parameter to DataBlock do? \nThe splitter parameter provides argument to tell fastai DataBlock to splits the data in a training and validation data set. For example create a 80% training und 20% validation random split of the data you could use splitter=RandomSplitter(valid_pct=0.2, seed = 42). With the random seed 42 we fix the randomness to get the same result for every run.\n How do we ensure a random split always gives the same validation set? \nComputer normally don’t generate truly random outputs they use a pseudo-random-generator which takes a random seed as an input. With random seed input we will get the same result for every run. Using a random seed, we can generate a random split that gives the same training and validation set.\n What letters are often used to signify the independent and dependent variables? \n\nx is independent\n\nAn independent variable is the variable you manipulate or vary in an experimental study to explore its effects. It’s called “independent” because it’s not influenced by any other variables in the study\n\ny is dependent\n\nA dependent variable is the variable that changes as a result of the independent variable manipulation. It’s the outcome you’re interested in measuring, and it “depends” on your independent variable.\n\n\n What the difference between crop, pad, and squish Resize() approaches? When might you choose one over the other? \nThe default of the fastai resize function is crop.\n\nCrop (Zuschneiden) –&gt; Fits the images to fit a square of the size requested, using the full width or height. This can result in losing some important details. For example lossing some key features that are cut out of the image.\nPad (Auffuellen) –&gt; Pad adds black pixels to reach the requested size. If we pad an image we have a lot of empty space, which is wasted computation for our model, and lowers the effective resolution of the images.\nSquish (Stauchen) –&gt; Squish stretches or squishes the image to the requested size. This can cause the image to take an unnatural form, leading to a model that learns that things look different.\n\nThe right resize function depends on the underlying images. If the features of the images are all over the place in the image crop can cut out important features. This can result in loss in information and squishing of padding may be more useful.\nAnother better method could be RandomResizedCrop, in which we crop a randomly selected region of the image. So every epoch, the model will see a different part of the image and will learn accordingly.\n What is data augmentation? Why is it needed? \nData augmentation refers to creating random variations of our input data, such that they appear different but do not change the meaning of the data. Examples of common data augmentation techniques for images are rotation, flipping, perspective warping, brightness changes, and contrast changes. Data augmentation is useful for the model to better understand the basic concept of what an object is and how the objects of interest are represented in images. Therefore, data augmentation allows machine learning models to generalize better. This is especially important when it can be slow and expensive to label data.\n Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data. \n\nThere is no bear in the image and the model has output option for not_a_bear.\nNighttime images are passed into the model.\nThe images vary in resolution. Low-resolution image.\nThe bear is really far or near the camera.\nThe model is very biased towards one type of features (eg. color.)\n\n What is the difference between item_tfms and batch_tfms? \n\nitem_tfms are transformations applied to a single data sample x on the CPU. Resize() is a common transform because the mini-batch of input images to a cnn must have the same dimensions. Assuming the images are RGB with 3 channels, then Resize() as item_tfms will make sure the images have the same with and height.\nbatch_tfms are applied to batched data samples (aka individual samples that have been collated into a mini-batch) on the GPU. They are faster and more efficient than item_tfms. A good example of these are the ones provided by aug_transform(). Inside are several batch-level augmentation that help many models.\n\n What is a confusion matrix? \nIn the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as error matrix, is specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one; in unsupervised learning it is usually called a matching matrix.\nEach row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class, of vise versa. The name stems from the fact that it makes it easy to see whether the system is confusing two classes.\n What does export save do? \nA model consists of two parts. The architecture and the trained parameters, the best way is to save both of these. In fastai you use the export method. This method even saves the definition of how to create your DataLoaders. This is important because otherwise you would have to redefine how to transform your data in order to use your model in production.\n What is it called when we use a model for getting predictions, instead of training? \nWhen we use a model for getting predictions, instead of training, we call it inference.\n What are IPyhton widgets? \nIPython widgets are GUI components that bring together Javascript und Python functionality in a web browser and can be created and used within a Jupyter notebook. One example of these interactive GUI components would be an upload button which can be created with the Python function widgets.FileUpload().\n When might you want to use CPU for deployment? When might GPU be better? \nGPUs are best for doing identical work in parallel. If you will analyzing single pieces of data at time (like a single image or single sentence), then CPUs may be more effective instead, especially with more market competition for CPU servers versus GPU servers. GPUs could be used if you collect user responses into a batch at a time, and perform inference on the batch. This my require the user to wait for model predictions. Additionally, there are many other complexities when it comes to GPU inference, like memory management and queuing of the batches.\n What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC? \nOne downside for using a server over a client that you will require a network connection and there will be some latency each time the model is called. Another negative point can be that some users may be concerned uploading sensitive data to your remote server. Managing the complexity and scaling the server can create additional overhead too, whereas if your model runs on the edge devices, each user is\n What are 3 examples of problems that could occur when rolling out a bear warning system in practice? \nThe model we trained will likely perform poorly when:\n\nHandling night-time images\nDealing with low-resolution images (ex: some smartphone images)\nThe model returns prediction too slowly to be useful\n\n What is “out of domain data”? \nOut of domain data is data that is significantly different in structure or style th those used to train the model. For instance, if there were no black-and-white images in the training data, the model may do poorly on black-and-white images.\n What is “domain shift”? \nThis is when the type of data changes gradually over time. For example, an insurance company is using a deep learning model as part of their pricing algorithm, but over time their customers will be different, with the original training data not being representative of current data, and the deep learning model being applied on effectively out-of-domain data.\n What are the 3 steps in the deployment process? \n\nManual process\n\nRun model in parallel\nHuman check all predictions\n\nLimited scope deployment\n\nCareful human supervision\nTime or geography limited\n\nGradual expansion\n\nGood reporting systems needed\nConsider what could go wrong"
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/subsite/your_deep_learning_journey_questions.html",
    "href": "posts/2023-08-14_your_deep_learning_journey/subsite/your_deep_learning_journey_questions.html",
    "title": "Questions - Chapter 1",
    "section": "",
    "text": "Back to blog post\n\n\n\nfastai book chapter 1\n\n\n\n\n\n\n\n\nLinks\n\n\n\n\nSource: Fastbook Chapter 1 questionnaire solutions (wiki)\n\n\n\n What is Deep Learning? \nDeep learning is a computer technique to extract anf transform data for that it uses multiple layers of neural networks. The layers are trained by alogrithms that minimze thier accuracy. In this way, the network learn to perform a specified task.\n Do you need these for Deep Learning?\n\nLots of Math (True/False)\nLots of Data (True/False)\nLots of expensive computers (True/False)\nA Phd (True/False) \nLots of Math (False)\nLots of Data (False)\nLots of expensive computers (False)\nA Phd (False)\n\n Name five areas where deep learning is now the best tool in the world? \n\nMedicine\n\nCancer detection\n\nSecurity\n\nSpam detection\n\nComputer vision\n\nClassification of Images\n\nPlaying Games\n\nChess, Go\n\nNatural language processing (NLP)\n\nsummerizing documents, classifying documents\n\n\n What was the name of the first device that was based on the principle of the artificial neuron? \nMark 1-Perceptron.\nFrank Rosenblatt further developed the artificial neuron to give it the ability to learn. Based on this he worked on building the first device that actually used these principles, the Mark ! Perceptron.\n Based on the book of the same name, what are the requirements for parallel distrubted processing? \nBased on the definition parallel distributed processing the requirements are: 1. A set of processing units 2. A stat of activation 3. An output function for each unit 4. A pattern of connectivity among units 5. A propagation rule for propagating pattern of activities through th network of conductivities. 6. An activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit. 7. A learning rule whereby patterns of connectivity are modified by experience. 8. An environment within which the system must operate.\n What were the tow theoretical misunderstandings that held back the field of neural networks? \nIn 1969, Marvin Minsky an Seymour Papert demonstrated in their book, “Perceptrons”, that a single layer of artificial neurons cannot learn simple, critical mathematical functions like XOR logic gate. While they subsequently demonstrated in the same book that additional layers can solve this problem, only the first insight was recognizes, leading to the start of the first AI winter.\nIn the 1980’s models with tow layers were being explored. Theoretically, it is possible to approximate any mathematical function using two layers of artificial neurons. However, in practices, these networks were too big and too slow. While it was demonstrated that adding additional layers improved performance, this insight was not acknowledged, and the second AI winter began. In this past decade, with increased data availability, and improvements in computer hardware (both in CPU performance but more importantly in GPU performance), neural networks are finally living up to its potential.\n What is a GPU? \nA GPU is a Graphics Processing Unit. They were specializes processing units designed to accelerate graphics redndering for gaming. Thanks to their unique capability to efficiently parallelize massive distributed computational processes, GPUs have successfully been applied to applications beyond their original remit. These optimizations and capability’s allow us to run and train neural networks hundreds of times faster than a regular CPU.\n Open a notebook and execute a cell containing: 1+1. What happens? \nIn Jupyter Notebook we can create code cells in an interactive manner. When we execute a cell containing some code, the code runs by Python and the output is displayed under the curren code cell.\nCode Cell: 1+1 Output under der Code Cell: 2\n Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen. \nToDo\n Complete the Jupyter Notebook online appendix (https://oreil.ly9uPZe). \nToDo\n Why is it hard to use traditional computer program to recognize images in a photo? \nWhen creating a normal computer program think about some steps and translate them into code. As Example we can write an algorithm to sort a list. But for recognizing an image or object it is tricky. We as human subconsciously learned a lot of features defining one object from an other. It is very difficult to manually code these complex patterns of shapes, textures, colors, and other features to recognize different objects and images.\n What did Samuel mean by “weight assignment”? \n“weight assignment” refers to the current values of the model parameters. Arthur Samuel further mentions an “ automatic means of testing the effectiveness of any current weight assignment ” and a “ mechanism for altering the weight assignment so as to maximize the performance ”. This refers to the evaluation and training of the model in order to obtain a set of parameter values that maximizes model performance.\n What term do we normally use in deep learning for what Samuel called “weights”? \nWeights are also called parameters.\n Draw a picture that summarizes Samuel`s view of a machine learning model. \n\n\n\nmachine learning model\n\n\n Why is it hard to understand why a deep learning model makes a particular prediction? \nAll kinds of machine learning models (including deep learning and traditional statical models) can be challenging to fully understand. Think of a linear regression model. Simply, we have some input variables/data that are multiplied by some weights, giving us an output. We can understand which variables are more important and which are less important based on their weights. A similar logic might apply for a small neural network with 1-3 layers. However, deep neural networks have hundreds, if not thousands, of layers. It is hard to determine which factors are important in determining the final output. The neurons in the network interact with each other, with the outputs of some neurons feeding into other neurons. Altogether, due to the complex nature of deep learning models, it is very difficult to understand why a neural network makes a given prediction.\nHowever, in some cases, recent research has made it easier to better understand a neural network’s prediction. For example, as shown in this chapter, we can analyze the sets of weights and determine what kind of features activate the neurons. When applying CNNs to images, we can also see which parts of the images highly activate the model. We will see how we can make our models interpretable later in the book.\n What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy? \nIf you regard a neural network as a mathematical function, it turns out to be a function which is extremely flexible depending on its weights. A mathematical proof called the universal approximation theorem shows that this function can solve any problem to any level of accuracy, in theory.\n What do you need in order to train a model? \nYou need a architecture, a general template for how that kind of model works internally. For training/fitting the model you need data to specialize the general architecture. To define how well a model does on a single prediction. We need to define a loss function, which determines how good the model performs. Do determine the loss we need labeled data, data indicating what it represent.\n How could a feedback loop impact the rollout of a predictive policing model? \nIn a predictive policing model, we might end up with a positive feedback loop, leading to a highly biased model with little predictive power. For example, we may want a model that would predict crimes, but we use information on arrests as a proxy . However, this data itself is slightly biased due to the biases in existing policing processes. Training with this data leads to a biased model. Law enforcement might use the model to determine where to focus police activity, increasing arrests in those areas. These additional arrests would be used in training future iterations of models, leading to an even more biased model. This cycle continues as a positive feedback loop.\n Do we always have to use 224x224-pixel images with the cat recogintion? \nNo, This is the standard size for historical reasons (old pretrained models require this size exactly), but you can pass pretty much anything. If you increase the size, you’ll often get a model with better results (since it will be able to focus on more details), but at the price of speed and memory consumption; the opposite is true if you decrease the size.\n What is the difference between classification and regression? \n\nClassification A classification model is one that attempts to predict a class, or category. That is, it’s predicting from a number of discrete possibilities.\nRegression A regression model is one that attempts to predict one or more numeric quantities, such as a temperature or a location.\n\n What is a validation set? What is a test set? Why do we need them? \n\nTraining set The data used for fitting the model, does not include any data from the validation set. (If there is enough data 80% is used for training)\nValidation set A set of data held out from training, used only for measuring how good the model is. (If there is enough data 20% is used for validation)\nTest set As we hold the validation data back from the training process, we can hold back a test set data even from ourselves. It cannot be used to improve the model, it can only be used to evaluate the model at the very end. (Take out some data for testing and split the rest to 80% for training and 20% for validation)\n\n What will fastai do if you don’t provide a validation set? \nIt will automatically create a validation dataset if no validation set is provided. By default fastai takes out 20% that is held out is randomly.\n Can we always use a random sample for a validation set? Why or why not? \nA good validation or test set should be representative of new data you will see in the future. Sometimes this isn’t true if a random sample is used. For example, for times series data, selecting sets randomly does not make sense. Instead, defining different time periods for the train, validation, and test set is a better approach.\n What is overfitting? Provide an example. \nOverfitting is the single most important and challenging issue when training for all machine learning. Training a model in such a way that it remembers specific features of the input data, rather than generalizing well to data not seen during training.\n What is a metic? How does it differ from loss? \nThe concept of a metric may remind you of loss, but there is an important distinction. The entire purpose of loss is to define a “measure of performance” that the training system can use to update weights automatically. In other words, a good choice for loss is a choice that is easy for stochastic gradient descent to use. But a metric is defined for human consumption, so a good metric is one that is easy for you to understand, and that hews as closely as possible to what you want the model to do. At times, you might decide that the loss function is a suitable metric, but that is not necessarily the case.\n How can pretrained models help? \nA model that has weights that have already been trained on some other dataset is called a pretrained model. You should nearly always use a pretrained model, because it means that your model, before you’ve even shown it any of your data, is already very capable. For instance, parts of pretrained models will handle edge, gradient, and color detection, which are needed for many tasks. Using pretrained models is the most important method we have to allow us to train more accurate models, more quickly, with less data, and less time and money.\n What is the “head” of a model? \nThe head of a model is the part that is newly added to be specific to the new dataset. So the other layers which were not replaced where already trained for what the model war originally thought for.\n What kinds of features do the early layers of a CNN find? How about the later layers? \nThe early layers learn simple features corners, edges, lines, circles. The later layers learn more advanced features like eyes, wheels, outlines of animals trees or humans.\n Are image models useful only for photos? \nNope! Image models can be useful for other types of images like sketches, medical data, etc.\nHowever, a lot of information can be represented as images . For example, a sound can be converted into a spectrogram, which is a visual interpretation of the audio. Time series (ex: financial data) can be converted to image by plotting on a graph. Even better, there are various transformations that generate images from time series, and have achieved good results for time series classification. There are many other examples, and by being creative, it may be possible to formulate your problem as an image classification problem, and use pretrained image models to obtain state-of-the-art results!\n What is an architecture? \nThe architecture is the template or structure of the model we are trying to fit. It defines the mathematical model we are trying to fit.\n What is segmantaion? \nCreating a model that can recognize the content of every individual pixel in an image is called segmentation. The result is a segmentation (mask) for which parts of the image correspond to the given label.\n What is y_range used for? When do we need is? \ny_range is being used to limit the values predicted when our problem is focused on predicting a numeric value in a given range (ex: predicting movie ratings, range of 0.5-5).\n What are “hyperparameters”? \nTraining models requires various other parameters that define how the model is trained. For example, we need to define how long we train for, or what the learning rate is used (how fast the model parameters are changed). These sorts of parameters are hyperparameters.\n What’s the best way to avoid failures when using AI in an organization? \n\nMake sure a training, validation, adn testing set is defined properly in order to evaluate the model in an appropriate manner.\nTry out a simple baseline, which future models should hopefully beat. Or even this simple baseline may be enough in some cases."
  },
  {
    "objectID": "posts/2023-06-30_welcome/welcome_post.html",
    "href": "posts/2023-06-30_welcome/welcome_post.html",
    "title": "hello world",
    "section": "",
    "text": "flora - janf - 2020\n\n\n\nThis is the first post on this blog. Seavas!\nHello, I’m Jan F. from west austria 🇦🇹 .  I like to learn and create new things. Here i take notes about these processes or outcomes ✌️"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Notes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n2023-09-09\n\n\npytorch tensor cheatsheet\n\n\n\n\n2023-06-30\n\n\nanaconda cheatsheet\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-09-24_data_ethics/subsite/data_ethics_questions.html",
    "href": "posts/2023-09-24_data_ethics/subsite/data_ethics_questions.html",
    "title": "Questions - Chapter 3",
    "section": "",
    "text": "Back to blog post\n\n\n\nfastai book chapter 3\n\n\n\n\n\n\n\n\nLinks\n\n\n\n\nSource: Fastbook Chapter 2 questionnaire solutions (wiki)\n\n\n\n Does ethics provide a list of “right answers”? \nx\n How can working with people of different background help when considering ethical questions? \nx\n What was the role of IBM Nazi Germany? Why did the company participate as they did? Why did the workers participate? \nx\n What was the role of the first person jailed in the VW diesel scandal? \nx\n What was the problem with a database of suspected gang members maintained by California law enforcement officials? \nx\n Why did Youtube’s recommendation algorithm recommend videos of partially clothed children to pedophiles, even although no employee at Google programmed this feature? \nx\n What are the problems with the centrality of metrics? \nx\n Why did Meetup.com not include gender in its recommendation system for tech meetups? \nx\n What are the six types of bias in machine learning, according to Suresh and Guttag? \nx\n Give to examples of historical race bias in the US \nx\n Where are most images in ImageNet from? \nx\n In the paper “Does Machine Learning Automate Moral Hazard and Error” why is sinusitis found to predictive of a stroke? \nx\n What is representation bias? \nx\n How are machines and people different, in terms of their use for making decisions? \nx\n Is disinformation the same as “fake news”? \nx\n Why is disinformation through auto-generated text particularly significant issues? \nx\n What are the five ethical lenses described by the Markkula Center? \nx\n Where is policy an appropriate tool for addressing data ethics issues? \nx"
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html",
    "title": "your deep learning journey",
    "section": "",
    "text": "fastai book chapter 1 - janf - 2023"
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#what-is-machine-learning",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#what-is-machine-learning",
    "title": "your deep learning journey",
    "section": "What is machine learning",
    "text": "What is machine learning\nThe idea is instead of telling the computer the exact steps required to solve a problem, show it examples of the problem to solve, and let it figure out how to solve it itself.\n\n\n\ntraining a machine learning model - fastai - 2023\n\n\n\nweight assignment\nautomatic means of testing the effectiveness\ncurrent weight assignment in terms of actual performance\nmechanism for altering the weight assignment so as to maximize the performance"
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#what-is-deep-learning",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#what-is-deep-learning",
    "title": "your deep learning journey",
    "section": "What is deep learning",
    "text": "What is deep learning\nDeep learning is specialty within machine learning that uses neural networks with multiple layers."
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#why-are-neural-network-great-for-machine-deep-learning",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#why-are-neural-network-great-for-machine-deep-learning",
    "title": "your deep learning journey",
    "section": "Why are neural network great for machine / deep learning",
    "text": "Why are neural network great for machine / deep learning\n\nIf you regard a neural network as a mathematical function, it turns out to be function that ist extremely flexible depending on its weights.\nA mathematical proof called the universal approximation theorem shows that this function can solve any problem to any level of accuracy.\nIn neural network we can use stochastic gradient descent (SGD).\nTo determine the actual performance we can define our models performance as its accuracy at predicting the correct answers."
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#modern-deep-learning-loop-and-jargon",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#modern-deep-learning-loop-and-jargon",
    "title": "your deep learning journey",
    "section": "Modern Deep Learning Loop and Jargon",
    "text": "Modern Deep Learning Loop and Jargon\n\n\n\nmodern deep learning loop - fastai - 2023\n\n\n\nArchitecture The template of the model that we trying to fit, the actual mathematical function that we’re passing the input data and parameters to.\nModel The combination of the architecture with a particular set of parameters.\nLabel The data that we trying to predict.\nParameters The values in the model that change what task it can do and that are updated through model training\nPredictions The results of the model are called predictions. The predictions are calculated from the independent variable, which is the data not including the labels.\nLoss Loss ist the measurement of the performance. The loss depends not only on the predictions, but also on the correct labels.\nFit / Train Update the parameters of the model such that the predictions of the model using the input data match the target labels.\nEpoch One complete pass through the input data (training set)"
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#limitations-inherent-to-machine-learning",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#limitations-inherent-to-machine-learning",
    "title": "your deep learning journey",
    "section": "Limitations Inherent to Machine Learning",
    "text": "Limitations Inherent to Machine Learning\n\nA model cannot be created without data.\nA model can learn to operate on only the patterns seen in the input data used to train it.\nThis learning approach creates only predictions, not recommended actions.\nIt’s not enough to just have examples of input data, we need labels for that data too."
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#classification-and-regression",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#classification-and-regression",
    "title": "your deep learning journey",
    "section": "Classification and Regression",
    "text": "Classification and Regression\n\nClassification A classification model is one that attempts to predict a class, or category. That is, it’s predicting from a number of discrete possibilities.\nRegression A regression model is one that attempts to predict one or more numeric quantities, such as a temperature or a location."
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#what-is-overfitting",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#what-is-overfitting",
    "title": "your deep learning journey",
    "section": "What is Overfitting",
    "text": "What is Overfitting\nOverfitting is the single most important and challenging issue when training for all machine learning. Training a model in such a way that it remembers specific features of the input data, rather than generalizing well to data not seen during training."
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#training-set-validation-sets-and-test-sets",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#training-set-validation-sets-and-test-sets",
    "title": "your deep learning journey",
    "section": "Training Set, Validation Sets and Test Sets",
    "text": "Training Set, Validation Sets and Test Sets\n\nTraining set The data used for fitting the model, does not include any data from the validation set. (If there is enough data 80% is used for training)\nValidation set A set of data held out from training, used only for measuring how good the model is. (If there is enough data 20% is used for validation)\nTest set As we hold the validation data back from the training process, we can hold back a test set data even from ourselves. It cannot be used to improve the model, it can only be used to evaluate the model at the very end. (Take out some data for testing and split the rest to 80% for training and 20% for validation)\n\n\n\n\n\n\n\nNote\n\n\n\nFor decision makers it is important to unsure to rally understand what a test and validation set is. For example you should never give out all the data to an external vender. Always hold some test data (test set) for your own validation of the final model."
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#what-is-a-cnn-convolutional-neural-network",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#what-is-a-cnn-convolutional-neural-network",
    "title": "your deep learning journey",
    "section": "What is a CNN (Convolutional neural network)",
    "text": "What is a CNN (Convolutional neural network)\nConvolutional neural network, a type of neural network that works particularly well for computer vision tasks."
  },
  {
    "objectID": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#pertrained-model-and-fine-tuning",
    "href": "posts/2023-08-14_your_deep_learning_journey/your_deep_learning_journey_post.html#pertrained-model-and-fine-tuning",
    "title": "your deep learning journey",
    "section": "Pertrained model and Fine-tuning",
    "text": "Pertrained model and Fine-tuning\nPretrained model A pretrained model has weights already been trained on some other dataset. You should nearly always use a pretrained model, because it means the your model, before you’ve even shown it any of your data, is already very capable. For instance. parts of pretrained models will handle edge, gradient, and color detection. which are needed for many tasks.\nTransfer learning Using a pretrained model for a task different to what it was originally trained for.\nFine-tuning A transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task that used for pretraining.\n\n\n\n\n\n\nNote\n\n\n\nUsing a pretrained model is the most important method we have to allow us to train more accurate models, more quickly, with less data, and less time and money."
  },
  {
    "objectID": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html",
    "href": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html",
    "title": "from model to production",
    "section": "",
    "text": "fastai book chapter 2 - janf - 2023"
  },
  {
    "objectID": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#drivetrain-approach",
    "href": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#drivetrain-approach",
    "title": "from model to production",
    "section": "Drivetrain Approach",
    "text": "Drivetrain Approach\nData products get more and more complex so we sometimes lose sight of the real problem we are trying to solve. The Drivetrain Approach aims to better couple the data science to the real business needs/real world problem and to use data not just to generate more data but to use data to produce actionable outcomes.\n\n\n\nDrive Train Approach - Designing great data products\n\n\n\n(Defined Objective) First we must define the objective / goal\n(Levers) Specify what inputs/levers of the system we control that influence the final outcome\n(Data) Determine what data to collect\n(Models) Building the predictive models"
  },
  {
    "objectID": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#dataloader-dataloaders-datablock",
    "href": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#dataloader-dataloaders-datablock",
    "title": "from model to production",
    "section": "DataLoader, DataLoaders, DataBlock",
    "text": "DataLoader, DataLoaders, DataBlock\n\nDataBlock is the data pipeline. A template that we create that has no data, but defines all the context on how to work with it. For example, how to split the data, the data types of or features and targets/labels, how to extract the labels from the underlying data (folders).\nDataLoader doesn’t care about preparing data, it expects the data is ready to go and only cares about how to load the data (e.g. whether in parallel or in a single process) as well as feeding the data to the model in batches (i.e. batch size)\nDataLoaders is a thin wrapper for more than one DataLoader.\n\nA DataLoaders, is a thin class that automatically generates multiple DataLoader objects based on the rules specified in our DataBlock\nExample of a DataLoaders with a DataBlock Api:\nbears = DataBlock(\nblocks =(ImageBlock, CategoryBlock),\nget_items=get_image_files,\nsplitter=RandomSplitter(valid_pct=0.2, seed=42),\nget_y=parent_label,\nitem_tfms=Resize(128)\n)\nThese are the main parameters of the DataBlock:\n\nblocks: is where you define the types of input and output data your model will work with. The first one is the independent (input) and the second one is dependent target. Usually you will have two input and output but you can have multiple input/output variables.\nget_items: tells fastai how and where to get the files/data when needed.\nsplitter: how to split the data in training and validation set. Seeds are optional for replicability.\nget_y: how to extract the target/label/variable (dependent) from the data."
  },
  {
    "objectID": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#data-augmentation",
    "href": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#data-augmentation",
    "title": "from model to production",
    "section": "Data Augmentation",
    "text": "Data Augmentation\nData augmentation refers to creating random variations of our input data, such that they appear different but do not change the meaning of the data. Examples of common data augmentation techniques for images are rotation, flipping, perspective warping, brightness changes and contrast changes. Data augmentation is useful for the model to better understand the basic concept of what an object is and how the objects of interest are represented in images. Therefore, data augmentation allows machine learning models to generalize better. This is especially important when it can be slow and expensive to label data."
  },
  {
    "objectID": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#clean-the-data-with-you-model",
    "href": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#clean-the-data-with-you-model",
    "title": "from model to production",
    "section": "Clean the Data with you Model",
    "text": "Clean the Data with you Model\nOn method to look at your model is visualizing it in a confusion matrix:\n\n\n\nconfusion matrix bears\n\n\nFor this example the rows represent all the black, grizzly and teddy bears in our dataset, respectively. The columns represent the images that the model predicted as black, grizzly and teddy bears, respectively. Therefore, the diagonal of the matrix shows the images that were classified correctly, and the off-diagonal cells represent those that were classified incorrectly.\nA confusion matrix is helpful to see where exactly our errors occurring 1. You can see if there are datasets errors (images with no bears or entries labeled incorrectly) 2. Or you can see if there is problem with the model (images with unusual lighting or blurred images)\nThe intuitive approach to doing data cleaning is to do it before you train a model. But you can also train a quick and simple model first, and then use it to help us with data cleaning. fastai includes a handy GUI for data cleaning called ImageClassifierCleaner that allows you to choose a category and the training versus validation set and view the highest-loss images (in order), along with menus to allow images to be selected for removal or relabeling:\ncleaner = ImageClassifierCleaner(learn)\ncleaner"
  },
  {
    "objectID": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#avoid-disasters",
    "href": "posts/2023-08-18_from_model_to_production/from_model_to_production_post.html#avoid-disasters",
    "title": "from model to production",
    "section": "Avoid Disasters",
    "text": "Avoid Disasters\nYou should always have in mind that it’s difficult to understand the behavior of a deep learning model. In a neural network the behavior emerges from the models attempt to match the training data, rather than being exactly defined.\nOne general problem is the out-of-domain data problem. That is to say, there may be data that our model sees in production that is very different from what it saw during training. There isn’t a complete technical solution to this problem, instead, we have to be careful about rolling out a deep learning model.\nAnother problem ist a domain is a domain shift, whereby the type of data that our model sees changes over time. For instance, an insurance company may use a deep learning model ass part of its pricing and risk algorithm, but over time the types of customers the company attracts and the types of risks it represents may change so much that the original training data is no longer relevant.\nHigh-Level approach to mitigate the risks on a roll-out\n\n\n\nMitigate risk on rollout"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "janf",
    "section": "",
    "text": "Hello, I’m jan f. from west austria 🇦🇹 . I like to learn and create new things. Here i take notes about these processes or outcomes ✌️"
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "janf",
    "section": "blog posts",
    "text": "blog posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nfrom model to production\n\n\n\n\n\nfastai book chapter 2\n\n\n\n\n\n\n2023-08-18\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\nyour deep learning journey\n\n\n\n\n\nfastai book chapter 1\n\n\n\n\n\n\n2023-08-14\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\nhello world\n\n\n\n\n\nThe first post on this blog\n\n\n\n\n\n\n2023-06-30\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "janf",
    "section": "",
    "text": "twitter\n  \n  \n    \n     Github\n  \n\n  \n  \n\n\nI’m jan f. from west austria 🇦🇹 . I like to learn and create new things. Here i take notes about these processes or outcomes ✌️\nEmail me at mail[at]janf.cc if you like!\nmore coming soon…"
  },
  {
    "objectID": "about.html#hey",
    "href": "about.html#hey",
    "title": "janf",
    "section": "",
    "text": "I’m jan f. from west austria 🇦🇹 . I like to learn and create new things. Here i take notes about these processes or outcomes ✌️\nEmail me at mail[at]janf.cc if you like!\nmore coming soon…"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html",
    "title": "pytorch tensors",
    "section": "",
    "text": "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of model, as well as the model’s parameters. Tensors are similar to NumPy’s arrays, expect that tensors can run on GPU or other hardware.\nPyTorch Tensor\nIntroduction to PyTorch Tensors"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#what-are-tensors",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#what-are-tensors",
    "title": "pytorch tensors",
    "section": "",
    "text": "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of model, as well as the model’s parameters. Tensors are similar to NumPy’s arrays, expect that tensors can run on GPU or other hardware.\nPyTorch Tensor\nIntroduction to PyTorch Tensors"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#creating-pytorch-tensors",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#creating-pytorch-tensors",
    "title": "pytorch tensors",
    "section": "Creating PyTorch Tensors",
    "text": "Creating PyTorch Tensors\n\nimport math\n\n\nimport torch\n\n\nFactory Method to create Tensor\nThe simplest way to create a tensor is with the torch.empty() call:\n\nx = torch.empty(3,4)\nprint(type(x))\nprint(x)\n\n&lt;class 'torch.Tensor'&gt;\ntensor([[1.2268e-35, 0.0000e+00, 3.0829e-44, 0.0000e+00],\n        [       nan, 0.0000e+00, 1.8314e+25, 6.9768e+22],\n        [8.5305e+02, 2.6778e+20, 3.0866e+29, 1.0170e+31]])\n\n\n\nthis creates a tensor using on of the numerous factory methods attached to the torch module.\nthe tensor itself is 2-dimensional, having 3 rows and 4 columns.\nthe type of the object returned is torch.Tensor, which is an alias for torch.FloatTensor, by default PyTorch tensors are 32-bit floating point numbers.\nthere are some random-looking values in the tensor. The torch.empty() call allocates memory for the tensor, but does not initialize it with any values - so what your’re seeing is whatever was in memory at the time of allocation.\n\nIf you want to initialize the tensor with some vales. Common cases are all zeros, all ones, or random values. The torch module provides factory methods for alle of these:\n\n# create a tensor full of zeros\nzeros = torch.zeros(2,3)\nprint(zeros)\n\n# create a tensor full of ones\nones = torch.ones(2,3)\nprint(ones)\n\n# create a tensor full of random values\ntorch.manual_seed(1779)\nrandom = torch.rand(2,3)\nprint(random)\n\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\ntensor([[0.3699, 0.5704, 0.4876],\n        [0.3391, 0.1535, 0.0455]])\n\n\n\n\nTerminology about tensors and thier number of dimensions\n\nYou will sometimes see a 1-dimensional tensor called a vector.\nA 2-dimensional tensor is often referred as a matrix.\nAnything with more than two dimensions is generally just called a tensor.\n\n\n\nRandom Tensor and Seeding\nSometimes you want the same random values for reproducibility. Manually setting your random number generator’s seed fixes the random outputs to get the same results.\n\ntorch.manual_seed(1729)\nrandom1 = torch.rand(2,3)\nprint(random1)\n\nrandom2 = torch.rand(2,3)\nprint(random2)\n\ntorch.manual_seed(1729)\nrandom3 = torch.rand(2,3)\nprint(random3)\n\nrandom4 = torch.rand(2,3)\nprint(random4)\n\ntensor([[0.3126, 0.3791, 0.3087],\n        [0.0736, 0.4216, 0.0691]])\ntensor([[0.2332, 0.4047, 0.2162],\n        [0.9927, 0.4128, 0.5938]])\ntensor([[0.3126, 0.3791, 0.3087],\n        [0.0736, 0.4216, 0.0691]])\ntensor([[0.2332, 0.4047, 0.2162],\n        [0.9927, 0.4128, 0.5938]])\n\n\nWhat you should see above is that random1 and random3 carry identical values, as do random2 and random4. Manually resetting the seed gives the same results when you compute the things again.\n\n\nTensor Shapes\nOften when you are performing operations on two or more tensors, they will need to be of the same shape - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the **torch.*_like()** methodes:\n\nx = torch.empty(2,2,3)\nprint(x.shape)\nprint(x)\n\nempty_like_x = torch.empty_like(x)\nprint(empty_like_x.shape)\nprint(empty_like_x)\n\nzeros_like_x = torch.zeros_like(x)\nprint(zeros_like_x.shape)\nprint(zeros_like_x)\n\nones_like_x = torch.ones_like(x)\nprint(ones_like_x.shape)\nprint(ones_like_x)\n\nrand_like_x = torch.rand_like(x)\nprint(rand_like_x.shape)\nprint(rand_like_x)\n\ntorch.Size([2, 2, 3])\ntensor([[[1.3368e-35, 0.0000e+00, 1.2282e-35],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n\n        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\ntorch.Size([2, 2, 3])\ntensor([[[1.1759e-09, 4.5806e-41, 1.2202e-35],\n         [0.0000e+00, 4.4842e-44, 0.0000e+00]],\n\n        [[1.1210e-43, 0.0000e+00, 1.2240e-35],\n         [0.0000e+00, 1.4013e-45, 0.0000e+00]]])\ntorch.Size([2, 2, 3])\ntensor([[[0., 0., 0.],\n         [0., 0., 0.]],\n\n        [[0., 0., 0.],\n         [0., 0., 0.]]])\ntorch.Size([2, 2, 3])\ntensor([[[1., 1., 1.],\n         [1., 1., 1.]],\n\n        [[1., 1., 1.],\n         [1., 1., 1.]]])\ntorch.Size([2, 2, 3])\ntensor([[[0.6128, 0.1519, 0.0453],\n         [0.5035, 0.9978, 0.3884]],\n\n        [[0.6929, 0.1703, 0.1384],\n         [0.4759, 0.7481, 0.0361]]])\n\n\nThe first new thing in the code cell above is the use of the .shape property on a tensor. This property contains a list of the extent of each dimension of a tensor - in our case, x is a three-dimensional tensor with shape 2x2x3. Then we created new tensor’s with .empty_like(), .zeros_like(), .ones_like(), .rand_like() methods. With .shape we can verify that x has the same size as our new tensors.\n\n\nCreate a Tensor with specific data directly\n\nsome_constants = torch.tensor([[3.141, 2.789], [1.234, 4.923]])\nprint(some_constants.shape)\nprint(some_constants)\n\nsome_intergers = torch.tensor((2,3,4,5,6,7,8,9,10,11))\nprint(some_intergers.shape)\nprint(some_intergers)\n\nmore_intergers = torch.tensor(((2,4,6), [3,6,9]))\nprint(more_intergers.shape)\nprint(more_intergers)\n\ntorch.Size([2, 2])\ntensor([[3.1410, 2.7890],\n        [1.2340, 4.9230]])\ntorch.Size([10])\ntensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\ntorch.Size([2, 3])\ntensor([[2, 4, 6],\n        [3, 6, 9]])\n\n\nUsing torch.tensor() is the most straightforward way to create a tensor if your already have data in a Python tuple or list. Nesting will result in multi-dimensional tensor.\nNote: torch.tensor() creates a copy of the data.\n\n\nUnderstanding Tensor Shapes\nConsider tensor shapes as the number of lists that a dimension holds. For instance, a tensor shaped (4,4,2) will have four elements, which all contain 4 elements, which in turn have 2 elements.\n\nThe first holds 4 elements.\nThe second holds 4 elements.\nThe third dimension holds 2 elements.\n\n\n\n\ntorch.Size([4,4,2”])\n\n\n\ntensor442 = torch.empty(4,4,2)\nprint(tensor442.shape)\nprint(tensor442)\n\ntorch.Size([4, 4, 2])\ntensor([[[1.1759e-09, 4.5806e-41],\n         [1.1759e-09, 4.5806e-41],\n         [0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00]],\n\n        [[0.0000e+00, 0.0000e+00],\n         [1.8788e+31, 1.7220e+22],\n         [2.1715e-18, 4.2533e-05],\n         [1.3148e+22, 5.4412e-05]],\n\n        [[6.5555e-10, 3.3058e+21],\n         [3.2722e+21, 8.2730e+20],\n         [5.3134e-08, 1.7264e-07],\n         [3.2480e-09, 2.3052e-12]],\n\n        [[1.8788e+31, 7.9303e+34],\n         [6.1949e-04, 1.8590e+34],\n         [7.7767e+31, 7.1536e+22],\n         [3.3803e-18, 2.0552e+32]]])\n\n\n\n\nData structures in tensors\n\n# [x]\n# ----------------------- \n# scalar\n# 0D (zero dimension)\nprint('create tensor:')\nd0 = torch.ones(1)\nprint(d0)\n\nprint('create tensor:')\nd0 = torch.tensor([1.])\nprint(d0)\n\nprint('get value 1:')\nprint(d0[0])\n\nprint('shape:')\nprint(d0.shape)\n\ncreate tensor:\ntensor([1.])\ncreate tensor:\ntensor([1.])\nget value 1:\ntensor(1.)\nshape:\ntorch.Size([1])\n\n\n\n# [x]\n# [x]\n# [x]\n# -----------------------\n# vector\n# 1D (one dimension)\nprint('create tensor:')\nd1 = torch.ones(3)\nprint(d1)\n\nprint('create tensor:')\nd1 = torch.tensor([1.,2.,3.])\nprint(d1)\n\nprint('get value 3:')\nprint(d1[2])\n\nprint('shape:')\nprint(d1.shape)\n\ncreate tensor:\ntensor([1., 1., 1.])\ncreate tensor:\ntensor([1., 2., 3.])\nget value 3:\ntensor(3.)\nshape:\ntorch.Size([3])\n\n\n\n# [x x x]\n# [x x x]\n# [x x x]\n# -----------------------\n# matrix\n# 2D (two dimension)\nprint('create tensor:')\nd2 = torch.ones(3,3)\nprint(d2)\n\nprint('create tensor:')\nd2 = torch.tensor([[1.,2.,3.],[4.,5.,6.],[7.,8.,9.]])\nprint(d2)\n\nprint('get value 4:')\nprint(d2[1,0])\n\nprint('shape:')\nprint(d2.shape)\n\ncreate tensor:\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])\ncreate tensor:\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\nget value 4:\ntensor(4.)\nshape:\ntorch.Size([3, 3])\n\n\n\n# [x x x] [x x x] [x x x]\n# [x x x] [x x x] [x x x]\n# [x x x] [x x x] [x x x]\n# -----------------------\n# tensor\n# 3D (3 dimension)\nprint('create tensor:')\nd3 = torch.ones(3,3,3)\nprint(d3)\n\nprint('create tensor:')\nd3 = torch.tensor([[[1.,1.,1.],[1.,1.,1.],[1.,1.,1.]],[[2.,2.,2.],[2.,5.,2.],[2.,2.,2.]],[[3.,3.,3.],[3.,3.,3.],[3.,3.,3.]]])\nprint(d3)\n\nprint('get value:')\nprint(d3[1,1,1])\n\nprint('shape:')\nprint(d3.shape)\n\ncreate tensor:\ntensor([[[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]],\n\n        [[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]],\n\n        [[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]]])\ncreate tensor:\ntensor([[[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]],\n\n        [[2., 2., 2.],\n         [2., 5., 2.],\n         [2., 2., 2.]],\n\n        [[3., 3., 3.],\n         [3., 3., 3.],\n         [3., 3., 3.]]])\nget value:\ntensor(5.)\nshape:\ntorch.Size([3, 3, 3])\n\n\n\n# dimension &gt; 3\n# -----------------------\n# tensor\n# XD (x &gt; 3 dimension)\n\nprint('create tensor:')\ndx = torch.ones(4,2,2,2)\nprint(dx)\n\ncreate tensor:\ntensor([[[[1., 1.],\n          [1., 1.]],\n\n         [[1., 1.],\n          [1., 1.]]],\n\n\n        [[[1., 1.],\n          [1., 1.]],\n\n         [[1., 1.],\n          [1., 1.]]],\n\n\n        [[[1., 1.],\n          [1., 1.]],\n\n         [[1., 1.],\n          [1., 1.]]],\n\n\n        [[[1., 1.],\n          [1., 1.]],\n\n         [[1., 1.],\n          [1., 1.]]]])\n\n\n\n\nTensor Data Types\nSetting the datatype of a tensor is possible a couple of ways:\n\na = torch.ones((2,3), dtype=torch.int16)\nprint(a)\n\nb = torch.rand((2,3), dtype=torch.float64) * 20\nprint(b)\n\nc = b.to(torch.int32)\nprint(c)\n\ntensor([[1, 1, 1],\n        [1, 1, 1]], dtype=torch.int16)\ntensor([[ 0.9956,  1.4148,  5.8364],\n        [11.2406, 11.2083, 11.6692]], dtype=torch.float64)\ntensor([[ 0,  1,  5],\n        [11, 11, 11]], dtype=torch.int32)\n\n\nThe simplest way to set underlying data type of a tensor is with an optional argument at creation time. At “a” we set dtype=torch.int16. Printing a shows that the data is 1 rather than 1. (1 int, 1. float)\nAnother thing to notice by printing out a tensor it also shows the specified dtype.\nAnother way to set the datatype is with the .to() method. In the cell above, we create a random floating point tensor b and den converted b to a 32-bit integer in c.\nPyTorch datatypes:\n\ntorch.bool\ntorch.int8\ntorch.uint8\ntorch.int16\ntorch.int32\ntorch.int64\ntorch.half\ntorch.float\ntorch.double\ntorch.bfloat"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#math-logic-with-tensors",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#math-logic-with-tensors",
    "title": "pytorch tensors",
    "section": "Math & Logic with Tensors",
    "text": "Math & Logic with Tensors\nBasic arithmetic with tensors and how tensor interact with simple scalars:\n\nones = torch.zeros(2,2) + 1\ntwos = torch.ones(2,2) * 2\nthrees = (torch.ones(2,2) * 7 - 1) / 2\nfours = twos ** 2\nsqrt2s = twos ** 0.5\n\nprint(ones)\nprint(twos)\nprint(threes)\nprint(fours)\nprint(sqrt2s)\n\ntensor([[1., 1.],\n        [1., 1.]])\ntensor([[2., 2.],\n        [2., 2.]])\ntensor([[3., 3.],\n        [3., 3.]])\ntensor([[4., 4.],\n        [4., 4.]])\ntensor([[1.4142, 1.4142],\n        [1.4142, 1.4142]])\n\n\nArithmetic operations between tensors and scalars, such as addition, subtraction, multiplication, division, and exponentiation are distributed over every element of the tensor.\nOperation between tow tensors also behave like you’d intuitively expect:\n\npowers2 = twos ** torch.tensor([[1,2], [3,4]])\nprint(powers2)\n\nfives = ones + fours\nprint(fives)\n\ndozens = threes * fours\nprint(dozens)\n\ntensor([[ 2.,  4.],\n        [ 8., 16.]])\ntensor([[5., 5.],\n        [5., 5.]])\ntensor([[12., 12.],\n        [12., 12.]])\n\n\nIt’s important to note that all of the tensors in the previous code cell were of identical shape. What happens when we try to perform a binary operation on tensor if dissimilar shape?\n\n# The following throws a run-time error. This is intentional.\n\na = torch.rand(2,3)\nb = torch.rand(3,2)\n\nprint(a * b)\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n\n\nIn general case, you cannot operate on tensors of different shape this way,even in a case like the call above, where the tensor have identical number of elements.\n\nIn Brief: Tensor Broadcasting\nThe exception to the same-shape rule is tensor broadcasting. Here’s an example:\n\nimport torch\n\nrand = torch.rand(2,4)\ndoubled = rand * (torch.ones(1,4)*2)\n\nprint(rand)\nprint(doubled)\n\ntensor([[0.2024, 0.5731, 0.7191, 0.4067],\n        [0.7301, 0.6276, 0.7357, 0.0381]])\ntensor([[0.4049, 1.1461, 1.4382, 0.8134],\n        [1.4602, 1.2551, 1.4715, 0.0762]])\n\n\nHow is it we get to multiply a 2x4 tensor by a 1x4 tensor?\nBroadcasting is a way to perform an operation between tensors that have similarities in their shapes. In the example above, the one-row, four-column tensor is multiplied by both rows of the two-row, four-column tensor.\n\n\n\nPytorch Broadcasting\n\n\nThis is an important operation in Deep Learning. The common example is multiplying a tensor of learning weights by a batch of input tensors, applying the operation to each instance in the batch separately, and returning a tensor of identical shape - just like our (2,4) * (1,4) example above returned a tensor of shape (2,4).\nThe rules of broadcasting are:\n\nEach tensor must have at least one dimension - no empty tensors.\nComparing the dimension sizes of the tow tensors, going from last to first:\n\nEach dimension must be equal of\nOne of the dimension must be of size 1, or\nDimension does not exist in one of the tensors\n\n\nTensors of identical shape, of course are trivially “broadcastable”, as you saw earlier.\nHere are some examples of situation that honor the above rules and allow broadcasting:\n\na = torch.ones(     4,  3,  2)\nprint(a)\n\ntensor([[[1., 1.],\n         [1., 1.],\n         [1., 1.]],\n\n        [[1., 1.],\n         [1., 1.],\n         [1., 1.]],\n\n        [[1., 1.],\n         [1., 1.],\n         [1., 1.]],\n\n        [[1., 1.],\n         [1., 1.],\n         [1., 1.]]])\n\n\n\nb = a * torch.rand(     3,  2) # 3rd & 2nd dims identical to a, dim 1 absent\nprint(b)\n\ntensor([[[0.0381, 0.2138],\n         [0.5395, 0.3686],\n         [0.4007, 0.7220]],\n\n        [[0.0381, 0.2138],\n         [0.5395, 0.3686],\n         [0.4007, 0.7220]],\n\n        [[0.0381, 0.2138],\n         [0.5395, 0.3686],\n         [0.4007, 0.7220]],\n\n        [[0.0381, 0.2138],\n         [0.5395, 0.3686],\n         [0.4007, 0.7220]]])\n\n\n\nc = a * torch.rand(     3,  1) # 3rd dim = 1, 2nd dim identical to a\nprint(c)\n\ntensor([[[0.8217, 0.8217],\n         [0.2612, 0.2612],\n         [0.7375, 0.7375]],\n\n        [[0.8217, 0.8217],\n         [0.2612, 0.2612],\n         [0.7375, 0.7375]],\n\n        [[0.8217, 0.8217],\n         [0.2612, 0.2612],\n         [0.7375, 0.7375]],\n\n        [[0.8217, 0.8217],\n         [0.2612, 0.2612],\n         [0.7375, 0.7375]]])\n\n\n\nd = a * torch.rand(     1,  2) # 3rd dim identical to a, 2nd dim = 1\nprint(d)\n\ntensor([[[0.8328, 0.8444],\n         [0.8328, 0.8444],\n         [0.8328, 0.8444]],\n\n        [[0.8328, 0.8444],\n         [0.8328, 0.8444],\n         [0.8328, 0.8444]],\n\n        [[0.8328, 0.8444],\n         [0.8328, 0.8444],\n         [0.8328, 0.8444]],\n\n        [[0.8328, 0.8444],\n         [0.8328, 0.8444],\n         [0.8328, 0.8444]]])\n\n\nLook closely at the values of each tensor above:\n\nThe multiplication operation that created b was broadcast over every ‘layer’ of a.\nFor c, the operation was broadcast over ever layer and row of a - every 3-element column is identical.\nFor d, we switched it around - now every row is identical, across layers and columns.\n\nOne example where broadcasting will fail:\n\na = torch.ones(     4,  3,  2)\n\nb = a * torch.rand(     4,  3)  # dimension must match last-to-first\n\nc = a * torch.rand(     2,  3)  # both 3rd & 2nd dims different\n\nd = a * torch.rand(0,)          # cant broadcast with an empty tensor\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#more-math-with-tensor",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#more-math-with-tensor",
    "title": "pytorch tensors",
    "section": "More Math with Tensor",
    "text": "More Math with Tensor\nPyTorch tensors have over three hundred operations that can be performed on them. Here a small sample from some of the major categories of operations.\n\n# common functions\na = torch.rand(2,4) * 2 - 1\nprint('Common functions:')\nprint(torch.abs(a))\nprint(torch.ceil(a))\nprint(torch.floor(a))\nprint(torch.clamp(a, -0.5, 0.5))\n\n# trigonemtric fucntion and thier inverses\nangles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\nsines = torch.sin(angles)\ninverses = torch.asin(sines)\nprint('\\nSine and arcsine:')\nprint(angles)\nprint(sines)\nprint(inverses)\n\n# bitwise operations\nprint('\\nBitwise XOR:') \nb = torch.tensor([1,5,11])\nc = torch.tensor([2,7,10])\nprint(torch.bitwise_xor(b,c))\n\n# comparisons:\nprint('\\nBroadcasted, element-wise equality comparison:')\nd = torch.tensor([[1.,2.],[3.,4.]])\ne = torch.ones(1,2) # many comparison ops support broadcasting!\nprint(torch.eq(d,e)) # returns a tensor of type bool\n\n# reductions:\nprint('\\nReduction ops:')\nprint(torch.max(d))         # returns a single-element tensor\nprint(torch.max(d).item())  # extracts the value from the returned tensor\nprint(torch.mean(d))        # average\nprint(torch.std(d))         # standard deviation\nprint(torch.prod(d))        # product of all numbers\nprint(torch.unique(torch.tensor([1,2,1,2,1,2]))) # filter unique elements\n\n# vector and linear algebra operations\nv1 = torch.tensor([1., 0., 0.])         # x unit vector\nv2 = torch.tensor([0.,1.,0.])           # y unit vector\nm1 = torch.rand(2,2)                    # random matrix\nm2 = torch.tensor([[3.,0.], [0.,3.]])   # three times identity matrix\n\nprint('\\nVector & Matrices:')\nprint(torch.cross(v2,v1))               # negative of z unit vector (v1 x v2 == -v2 x v1)\nprint(m1)\nm3 = torch.matmul(m1,m2)\nprint(m3)                               # 3 times m1\nprint(torch.svd(m3))                    # singular value decomposition\n\nCommon functions:\ntensor([[0.0792, 0.3893, 0.6054, 0.3429],\n        [0.1310, 0.9869, 0.5530, 0.2932]])\ntensor([[1., -0., -0., -0.],\n        [1., -0., 1., -0.]])\ntensor([[ 0., -1., -1., -1.],\n        [ 0., -1.,  0., -1.]])\ntensor([[ 0.0792, -0.3893, -0.5000, -0.3429],\n        [ 0.1310, -0.5000,  0.5000, -0.2932]])\n\nSine and arcsine:\ntensor([0.0000, 0.7854, 1.5708, 2.3562])\ntensor([0.0000, 0.7071, 1.0000, 0.7071])\ntensor([0.0000, 0.7854, 1.5708, 0.7854])\n\nBitwise XOR:\ntensor([3, 2, 1])\n\nBroadcasted, element-wise equality comparison:\ntensor([[ True, False],\n        [False, False]])\n\nReduction ops:\ntensor(4.)\n4.0\ntensor(2.5000)\ntensor(1.2910)\ntensor(24.)\ntensor([1, 2])\n\nVector & Matrices:\ntensor([ 0.,  0., -1.])\ntensor([[0.7016, 0.6826],\n        [0.9413, 0.4460]])\ntensor([[2.1048, 2.0479],\n        [2.8240, 1.3380]])\ntorch.return_types.svd(\nU=tensor([[-0.6835, -0.7299],\n        [-0.7299,  0.6835]]),\nS=tensor([4.2305, 0.7013]),\nV=tensor([[-0.8273,  0.5617],\n        [-0.5617, -0.8273]]))\n\n\nThis a small sample of more details and the full inventory of math functions."
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#altering-tensors-in-place",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#altering-tensors-in-place",
    "title": "pytorch tensors",
    "section": "Altering Tensors in Place",
    "text": "Altering Tensors in Place\nMost binary operations on tensors will return a third, new tensor. When we say c = a * b (where a and b are tensors), the new tensor c will occupy a region of memory distinct from the other tensors.\nThere are times, though, that you may whish to alter a tensor in place - for example. if you’re doing an element-wise computation where you can discard intermediate value. For this, most of the math function have a version with an underscore(_) that will alter a tensor in place.\nFor example:\n\na = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\nprint('a:')\nprint(a)\nprint(torch.sin(a))     # this operation creates a new tensor in memory\nprint(a)                # a has not changed\n\nb = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\nprint('\\nb:')\nprint(b)\nprint(torch.sin_(b))    # note the underscore\nprint(b)                # b has changed\n\na:\ntensor([0.0000, 0.7854, 1.5708, 2.3562])\ntensor([0.0000, 0.7071, 1.0000, 0.7071])\ntensor([0.0000, 0.7854, 1.5708, 2.3562])\n\nb:\ntensor([0.0000, 0.7854, 1.5708, 2.3562])\ntensor([0.0000, 0.7071, 1.0000, 0.7071])\ntensor([0.0000, 0.7071, 1.0000, 0.7071])\n\n\nFor arithmetic operations, there are functions that behave similarly:\n\na = torch.ones(2,2)\nb = torch.rand(2,2)\n\nprint('Before: ')\nprint(a)\nprint(b)\nprint('\\nAfter adding:')\nprint(a.add_(b))\nprint(a)\nprint(b)\nprint('\\nAfter multiplying')\nprint(b.mul_(b))\nprint(b)\n\nBefore: \ntensor([[1., 1.],\n        [1., 1.]])\ntensor([[0.9289, 0.6293],\n        [0.6264, 0.4704]])\n\nAfter adding:\ntensor([[1.9289, 1.6293],\n        [1.6264, 1.4704]])\ntensor([[1.9289, 1.6293],\n        [1.6264, 1.4704]])\ntensor([[0.9289, 0.6293],\n        [0.6264, 0.4704]])\n\nAfter multiplying\ntensor([[0.8628, 0.3960],\n        [0.3924, 0.2212]])\ntensor([[0.8628, 0.3960],\n        [0.3924, 0.2212]])\n\n\nNote that these in-place arithmetic functions are methods an the torch.Tensor object, not attached to the torch module like many other functions (e.g. torch.sin()). As you can see from a.add_(b), the calling tensor is the one that gets changed in place.\nThere is another option for placing the result of computation in an existing, allocated tensor. Many of the methods and functions we’ve seen so far - including creation methods! - have an out argument that lets you specify a tensor to receive the output. If the out tensor is the correct shape an dtype, this can happen without a new memory allocation:\n\na = torch.rand(2,2)\nb = torch.rand(2,2)\nc = torch.zeros(2,2)\n\nold_id = id(c)\n\nprint(c)\nd = torch.matmul(a,b, out=c)\nprint(c)                    # contents of c have changed\n\nassert c is d               # test c & d are same objects, not just containing equal values\nassert id(c), old_id        # make sure that our new c is the same object as the old one\n\ntorch.rand(2,2, out=c)      # works for creation too!\nprint(c)                    # c has changed again\nassert id(c), old_id        # still the same object!\n\ntensor([[0., 0.],\n        [0., 0.]])\ntensor([[0.5694, 0.1489],\n        [0.8242, 0.4668]])\ntensor([[0.2138, 0.5395],\n        [0.3686, 0.4007]])"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#copying-tensors",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#copying-tensors",
    "title": "pytorch tensors",
    "section": "Copying Tensors",
    "text": "Copying Tensors\nAs with any object in Python, assigning a tensor to a variable makes the variable a label of the tensor, and does not copy it. For example.\n\na = torch.ones(2,2)\nb = a\n\na[0][1] = 561   # we change a ...\nprint(b)        # and b is also altered\n\ntensor([[  1., 561.],\n        [  1.,   1.]])\n\n\nBut what is you wand a separate copy of the data to work on? The clone() method is there for you:\n\na = torch.ones(2,2)\nb = a.clone()\n\nassert b is not a       # differen objects in  memory ...\nprint(torch.eq(a,b))    # ... but still with the same contents\n\na[0][1] = 561\nprint(b)\n\ntensor([[True, True],\n        [True, True]])\ntensor([[1., 1.],\n        [1., 1.]])\n\n\nThere is an important thing to be aware of when using clone(). If your source tensor has autograd, enabled then so will the clone. This will be covered more deeply in the video on autograd, but if you want the light version of the details, continue on.\nIn many cases, this will be what you want. For example, if your model has multiple computations paths in its forward() method, and both the original tensor and ist clone contribute to the model’s output, then to enable model learning you want autograd turned on for both tensors. If your source tensor has autograd enabled (which it generally will if it’s a set of learning weights or derived from a computation involving the weights), then you’ll get the result you want.\nOn the other hand, if you’re doing a computation where neither the original tensor nor its clone need to track gradients, then as long as the source tensor has autograd turned off, you’re good to go.\nThere is a third case, though: imagine you’re performing a computation in your model’s forward() function, where gradients are turned on for everything by default, but you want to pull out some values mid-stream to generate some metrics. In this case, you don’t want the clone copy of your source tensor to track gradients - performance is improved with autograd’s history tracking turned off. For this, you can use .detach() method on the source tensor:\n\na = torch.rand(2,2, requires_grad=True)     #  turn on autograd\nprint(a)\n\nb = a.clone()\nprint(b)\n\nc = a.detach().clone()\nprint(c)\n\nprint(a)\n\ntensor([[0.2024, 0.5731],\n        [0.7191, 0.4067]], requires_grad=True)\ntensor([[0.2024, 0.5731],\n        [0.7191, 0.4067]], grad_fn=&lt;CloneBackward0&gt;)\ntensor([[0.2024, 0.5731],\n        [0.7191, 0.4067]])\ntensor([[0.2024, 0.5731],\n        [0.7191, 0.4067]], requires_grad=True)\n\n\nWhat’s happening here ?\n\nWe create a with requires_grad=True on. We haven’t covered this optional argument yet, but will during the unit on autograd.\nWhen we print a, it informs us that the property requires_grad=True - this means that autograd and computation history tracking are turned on.\nWe clone a an label it b. When we print b, we can see that it’s tracking its computation history - it has inherited a’s autograd settings, and added to the computation history.\nWe clone a into c, but we call detach() first.\nPrinting c, we see no computation history, and no requires_grad=True.\n\nThe detach() method detaches the tensor from its computation history. It says “do whatever comes next as if autograd was off”. It does this without changing a - you can see that when we print a again at the end, it retains its requires_grad=True property."
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#moving-to-gpu",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#moving-to-gpu",
    "title": "pytorch tensors",
    "section": "Moving to GPU",
    "text": "Moving to GPU\nOne of the major advantage of PyTorch is its robust acceleration on CUDA-compatible Nividia GPUs. (“CUDA” stands for Compute Unified Device Architecture, which is Nvidia’s platform for parallel computing). So far, everything we’ve done has been on CPU. How do we move to the faster hardware?\nFirst, we should check whether a GPU is available, with the is_available() method.\nNote: If you do not have a CUDA-compatible GPU and CUDA divers installed, the executable cells in this section will not execute any GPU-related code.\n\nif torch.cuda.is_available():\n    print('We have GPU!')\nelse:\n    print('Sorry, CPU only')\n\nWe have GPU!\n\n\nOnce we’ve determined that one or more GPUs is available, we need to put out data someplace where the GPU can see it. Your GPU does computation on data in your computers RAM. Your GPU has dedicated memory attached to it. Whenever you want to perform a computation on a device, you must move all the data needed for that computation to memory accessible by that device. (Colloquially, “moving the data to memory accessible by the GPU” is shorted to, “moving the data to the GPU”.)\nThere multiple ways to get your data onto your target device. Yo may do it at creation time:\n\nif torch.cuda.is_available():\n    gpu_rand = torch.rand(2,2,device='cuda')\n    print(gpu_rand)\nelse:\n    print('Sorry, GPU only')\n\ntensor([[0.3344, 0.2640],\n        [0.2119, 0.0582]], device='cuda:0')\n\n\nBy default, new tensor are created ont the CPU, so we have to specify when we want to create out tensor on the GPU with the optional device argument. You can see when we print the new tensor, PyTorch informs us which device it’s on (if it’s not on CPU).\nYou can query the number of GPUs with torch.cuda.device_count(). If you have more than one GPU, you can specify them by index: device=‘cuda:0’, device=‘coda:1’, etc.H\nAs a coding practice, specifying our devices everywhere with string constants is pretty fragile. In an ideal world, your code would perform robustly wheter you’re on CPU or GPU hardware. You can do this by creating a device handle that can be passed to your tensors instead of a string:\n\nif torch.cuda.is_available():\n    my_device = torch.device('cuda')\nelse:\n    my_device = torch.device('cpu')\nprint('Device: {}'.format(my_device))\n\nx = torch.rand(2,2, device=my_device)\nprint(x)\n\nDevice: cuda\ntensor([[0.0024, 0.6778],\n        [0.2441, 0.6812]], device='cuda:0')\n\n\nIf you have an existing tensor living on one device, you can move it to another with the to() method. The following line of code creates a tensor on CPU, and moves it to whichever device handle you acquired in the previous cell.\n\ny = torch.rand(2,2)\ny = y.to(my_device)\n\nIt is important to know that in order to do computation involving tow or more tensors, all of the tensors must be on the same device. The following code will throw a runtime error, regardless of whether you have a GPU device available:\n\nx = torch.rand(2,2, device='cpu')\ny = torch.rand(2,2, device='cuda')\n\nz = x + y # exception will be thrown\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#manipulating-tensors-shapes",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#manipulating-tensors-shapes",
    "title": "pytorch tensors",
    "section": "Manipulating Tensors Shapes",
    "text": "Manipulating Tensors Shapes\nSometimes, you’ll need to change the chape of your tensor. Below. we’ll look at a few common cases, and how to handle them.\n\nchanging the Number or Dimensions\nOne chase where you might need to change the number of dimension is passing a single instance of input to your model. PyTorch models generally expect batches of input.\nFor example, imagine having a model that works on 3 x 226 x 226 images - a 226-pixel square with 3 color channels. When you load and transform it, you’ll get a tensor of shape (3,226,226). Your model, though, is expecting input of shape (N, 3, 226, 226), where N is the number of images in the batch. So how do you make a batch of one?\n\na = torch.rand(3,226,226)\nb = a.unsqueeze(0)\n\nprint(a.shape)\nprint(b.shape)\n\ntorch.Size([3, 226, 226])\ntorch.Size([1, 3, 226, 226])\n\n\nThe unsqueeze() method adds a dimension of extent 1. unsqueeze(0) adds it as a new zeroth dimension - now you have a batch of one!\nSo if that’s unsqueezing? What do we mean by squeezing? We’re taking advantage of the fast that any dimension of extent 1 does not chang the number of elements in the tensor.\n\nc = torch.rand(1,1,1,1,1)\nprint(c)\n\ntensor([[[[[0.5731]]]]])\n\n\nContinuing the example above, let’s say the model’s output is a 20-element vector for each input. You would then expect the output to have shape (N,20), where N is the number of instances in the input batch. That means that for our single-input batch, we’ll get an output of shape(1,20).\nWhat if you want to do some non-batched computation with that output - something that’s just expecting a 20-element vector?\n\na = torch.rand(1,20)\nprint(a.shape)\nprint(a)\n\nb = a.squeeze(0)\nprint(b.shape)\nprint(b)\n\nc = torch.rand(2,2)\nprint(c.shape)\n\nd = c.squeeze(0)\nprint(d.shape)\n\ntorch.Size([1, 20])\ntensor([[0.2330, 0.8441, 0.9004, 0.3995, 0.6324, 0.9464, 0.0113, 0.5183, 0.9807,\n         0.6545, 0.4144, 0.0696, 0.4648, 0.4491, 0.6265, 0.9411, 0.4922, 0.5461,\n         0.5396, 0.3053]])\ntorch.Size([20])\ntensor([0.2330, 0.8441, 0.9004, 0.3995, 0.6324, 0.9464, 0.0113, 0.5183, 0.9807,\n        0.6545, 0.4144, 0.0696, 0.4648, 0.4491, 0.6265, 0.9411, 0.4922, 0.5461,\n        0.5396, 0.3053])\ntorch.Size([2, 2])\ntorch.Size([2, 2])\n\n\nYou can see from the shape that our 2-dimensional tensor is now 1-dimensional, and if you look closely at the output of the cell above you’ll see that printing a shows an “extra” set of square brackets [] due to having an extra dimension.\nYou may only squeeze() dimension of extent 1. See above where we try to squeeze a dimension of size 2 in c, and get back the same shape we started with. Calls to squeeze() and unsqueeze() can only act on dimensions of extent 1 because to do otherwise would chang the number of elements in the tensor.\nAnother place you might use unsqueeze() is to ease broadcasting. Recall the example above where we had the following code:\n\na = torch.ones(4,3,2)\n\nc = a * torch.rand(   3,1) # 3rd dim = 1, 2nd dim identical to a\nprint(c)\n\ntensor([[[0.7765, 0.7765],\n         [0.3534, 0.3534],\n         [0.7016, 0.7016]],\n\n        [[0.7765, 0.7765],\n         [0.3534, 0.3534],\n         [0.7016, 0.7016]],\n\n        [[0.7765, 0.7765],\n         [0.3534, 0.3534],\n         [0.7016, 0.7016]],\n\n        [[0.7765, 0.7765],\n         [0.3534, 0.3534],\n         [0.7016, 0.7016]]])\n\n\nThe net effect of that was to broadcast the operation over dimensions 0 and 2, causing the random, 3 x 1 tensor to be multiplied element-wise by every 3-element column in a.\nWhat if the random vector hat just been 3-element vector? We’d lose the ability to do the broadcast, because the final dimensions would not match up according to the broadcasting rules. unsqueeze() comes to the rescue:\n\na = torch.ones(4,3,2)\nb = torch.rand(   3)    # trying to multiply a * b give a runtime error\nc = b.unsqueeze(1)      # change to a 2-dimensional tensor, adding new dim at the end\nprint(c.shape)\nprint(a * c)\n\ntorch.Size([3, 1])\ntensor([[[0.6826, 0.6826],\n         [0.9413, 0.9413],\n         [0.4460, 0.4460]],\n\n        [[0.6826, 0.6826],\n         [0.9413, 0.9413],\n         [0.4460, 0.4460]],\n\n        [[0.6826, 0.6826],\n         [0.9413, 0.9413],\n         [0.4460, 0.4460]],\n\n        [[0.6826, 0.6826],\n         [0.9413, 0.9413],\n         [0.4460, 0.4460]]])\n\n\nThe squeeze() and unsqueeze() methods also have in-place versions, squeeze_() and unsqueeze_():\n\nbatch_me = torch.rand(3,226,226)\nprint(batch_me.shape)\nbatch_me.unsqueeze_(0)\nprint(batch_me.shape)\n\ntorch.Size([3, 226, 226])\ntorch.Size([1, 3, 226, 226])\n\n\nSometimes you’ll want to change the shape of a tensor more radically, while still preserving the number of elements and their contents. One case where this happens is at the interface between a convolutional layer of a model and a linear layer of the model - this is common in image classification models. A convolutional kernal will yield an output tensor of shape features x width x height, but the following linear layer expects a 1-dimensional input. reshape() will do this for you, provided that the dimensions you request yield the same number of elements as the input tensor has:\n\noutput3d = torch.rand(6,20,20)\nprint(output3d.shape)\n\ninput1d = output3d.reshape(6 * 20 * 20)\nprint(input1d.shape)\n\n# can also call it as a method on the torch module:\nprint(torch.reshape(output3d, (6 * 20 * 20,)).shape)\n\ntorch.Size([6, 20, 20])\ntorch.Size([2400])\ntorch.Size([2400])\n\n\n(Note: The (6 * 20 * 20) argument in the final line of the cell above is because PyTorch expects a tuple when specifying a tensor shape - but when the shape is the first argument of a method, it lets us cheat and just use a series of integers. Here, we had to add the parentheses and comma to convince the method that is really a one-element tuple.)\nWhen it can, reshape() wil return a view on the tensor to be changed - that is a separate tensor object looking at the same underlying region of memory. This is important: That means any change made to the source tensor will be reflected in the view on that tensor, unless you clone() it.\nThere are conditions, beyond the scope of this introduction, where reshape() has to return a tensor carrying a copy of the data. For more information, see the docs."
  },
  {
    "objectID": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#pytorch-numpy-bridge",
    "href": "notes/2023-09-09_pytorch_tensors/pytorch_tensors.html#pytorch-numpy-bridge",
    "title": "pytorch tensors",
    "section": "Pytorch-Numpy Bridge",
    "text": "Pytorch-Numpy Bridge\nIn the section above on broadcasting, it was mentioned that PyTorch’s broadcast semantics are compatible with NumPy’s - but the kinship between PyTorch and NumPy goes even deeper than that.\nIf you have existing ML of scientific code with data stored in NumPy ndarrays, you may wish to express that same data as PyTorch tensors, whether to take advantage of PyTorch’s GPU acceleration, or its efficient abstractions for building ML models. It’s easy to switch between ndarrays and PyTorch tensors:\n\nimport numpy as np\n\nnumpy_array = np.ones((2,3))\nprint(numpy_array)\n\npytorch_tensor = torch.from_numpy(numpy_array)\nprint(pytorch_tensor)\n\n[[1. 1. 1.]\n [1. 1. 1.]]\ntensor([[1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\n\n\nPyTorch creates a tensor of the same shape and containing the same data as the NumPy array, going so far as to keep NumPy,s default 64bit float data type.\nThe conversion can just easily go the other way:\n\npytorch_rand = torch.rand(2,3)\nprint(pytorch_rand)\n\nnumpy_rand = pytorch_rand.numpy()\nprint(numpy_rand)\n\ntensor([[0.2587, 0.9526, 0.5603],\n        [0.8715, 0.9484, 0.7122]])\n[[0.25874352 0.9526257  0.56027913]\n [0.87152576 0.9484055  0.712178  ]]\n\n\nIt is important to know that these converted objects are using the same underlying memory as their source objects, meaning that changes to one are reflected in the other:\n\nnumpy_array[1,1] = 23\nprint(pytorch_tensor)\n\npytorch_rand[1,1] = 17\nprint(numpy_rand)\n\ntensor([[ 1.,  1.,  1.],\n        [ 1., 23.,  1.]], dtype=torch.float64)\n[[ 0.25874352  0.9526257   0.56027913]\n [ 0.87152576 17.          0.712178  ]]"
  }
]